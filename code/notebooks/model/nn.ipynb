{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8aff13",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "from keras_tuner import HyperParameters, Hyperband\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.util import is_laptop\n",
    "from utils.model_eval import mean_absolute_percentage_error\n",
    "from utils.data import get_normalized_data, get_normalized_transformed_data\n",
    "\n",
    "import pandas as pd, numpy as np, tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f54952",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81564d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = get_normalized_data()\n",
    "\n",
    "X_train, y_train = train\n",
    "X_val, y_val = val\n",
    "X_test, y_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b6902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HyperParameters()\n",
    "hp.Int('n_layers', min_value = 4, max_value = 15)\n",
    "hp.Int('n_units', min_value = 32, max_value = 512, step = 32)\n",
    "hp.Int('epochs', min_value = 50, max_value = 1000, step = 50)\n",
    "\n",
    "hp.Float('penalty', min_value = 1e-4, max_value = 1, sampling = 'log')\n",
    "\n",
    "hp.Choice('activation', ['relu', 'elu', 'softmax'])\n",
    "hp.Choice('optimizer', ['adam', 'rmsprop', 'adamax'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_tuner(hp):\n",
    "    n_units = hp.get('n_units')\n",
    "    n_layers = hp.get('n_layers')\n",
    "    activation = hp.get('activation')\n",
    "    penalty = hp.get('penalty')\n",
    "    optimizer = hp.get('optimizer')\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(units = n_units, activation = activation, kernel_regularizer=l2(penalty), input_shape = (X_train.shape[1], )))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    for _ in range(n_layers):\n",
    "        model.add(tf.keras.layers.Dense(units = n_units, activation = activation, kernel_regularizer=l2(penalty)))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units = n_units, activation = activation, kernel_regularizer=l2(penalty)))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units = 1, activation = 'linear'))\n",
    "\n",
    "    model.compile(optimizer = optimizer, loss = mean_absolute_percentage_error)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf823c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_units = 64, activation = 'elu', penalty =  0.00168, n_layers = 11, optimizer = 'rmsprop'):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape = (X_train.shape[1], )))\n",
    "    model.add(tf.keras.layers.Dense(units = n_units, activation = activation, kernel_regularizer=l2(penalty)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    for _ in range(n_layers):\n",
    "        model.add(tf.keras.layers.Dense(units = n_units, activation = activation, kernel_regularizer=l2(penalty)))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units = n_units, activation = activation, kernel_regularizer=l2(penalty)))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units = 1, activation = 'linear'))\n",
    "\n",
    "    model.compile(optimizer = optimizer, loss = mean_absolute_percentage_error)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f9ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e7ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs = 750, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81949fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5d2a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "# Define the TensorBoard callback\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "tuner = Hyperband(build_model_tuner, hyperparameters = hp, objective = 'val_loss', max_epochs = 100, project_name = \"Try-2024-4-30\")\n",
    "tuner.search(X_train, y_train, validation_data = (X_val, y_val), callbacks = [tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fcd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, sys\n",
    "stdout_buffer = io.StringIO()\n",
    "sys.stdout = stdout_buffer\n",
    "tuner.results_summary(num_trials = -1)\n",
    "sys.stdout = sys.__stdout__\n",
    "trials = stdout_buffer.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09536494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_cast(value):\n",
    "    if value.isdigit():\n",
    "        return int(value)\n",
    "    try:\n",
    "        return float(value)\n",
    "    except:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eed4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_list = [item.split('\\n') for item in trials.split('\\n\\n')]\n",
    "columns  = ['trial', 'n_layers', 'n_units', 'epochs', 'penalty', 'activation', 'optimizer', 'score']\n",
    "data = []\n",
    "for trial in trials_list[1:]:\n",
    "    data.append([safe_cast(trial[i].split()[1]) for i in [0, 2, 3, 4, 5, 6, 7, 12]])\n",
    "df = pd.DataFrame(data, columns = columns)\n",
    "df = df.set_index('trial')\n",
    "df = df.sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8faac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorboard.backend.event_processing import event_accumulator\n",
    "#best_trial = tuner.oracle.get_best_trials()[0].trial_id\n",
    "#trials = tuner.results_summary(num_trials=-1, )\n",
    "trials = tuner.get_best_trials(num_trials = -1)\n",
    "trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_history(best_trial):\n",
    "\n",
    "  acc = []\n",
    "  val_acc = []\n",
    "  loss = []\n",
    "  val_loss = []\n",
    "\n",
    "  for set_data in ['train', 'validation']:\n",
    "    if set_data == 'train':\n",
    "      ea = event_accumulator.EventAccumulator('./logs/Try-2024-4-30/trial_' + best_trial + '/execution0/' + set_data)\n",
    "      ea.Reload()\n",
    "      for i in range(len(ea.Scalars('epoch_loss'))):\n",
    "        acc.append(ea.Scalars('epoch_acc')[i][2])\n",
    "        loss.append(ea.Scalars('epoch_loss')[i][2])\n",
    "        #lr.append(ea.Scalars('epoch_lr')[i][2])\n",
    "\n",
    "  if set_data == 'validation':\n",
    "      ea = event_accumulator.EventAccumulator('logs/scalars/trial_' + best_trial + '/execution0/' + set_data)\n",
    "      ea.Reload()\n",
    "      for i in range(len(ea.Scalars('epoch_loss'))):\n",
    "        val_acc.append(ea.Scalars('epoch_acc')[i][2])\n",
    "        val_loss.append(ea.Scalars('epoch_loss')[i][2])\n",
    "\n",
    "  return acc, val_acc, loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d2cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, val_acc, loss, val_loss = extract_history(best_trial)\n",
    "\n",
    "print(acc, val_acc, loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d610d9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "best_model = tuner.get_best_models()[0]\n",
    "best_model.save(f'./saved_models/nn-{date.today()}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be45d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.fit(X_train, y_train, batch_size = 256, epochs = 100, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394976bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.squeeze(model.predict(X_test))\n",
    "y_true = y_test.values\n",
    "mape = tf.metrics.mean_absolute_percentage_error(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
