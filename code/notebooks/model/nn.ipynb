{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea8aff13",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "from keras_tuner import HyperParameters, Hyperband\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.util import is_laptop\n",
    "from utils.model_eval import mean_absolute_percentage_error\n",
    "from utils.data import get_normalized_data, get_normalized_transformed_data\n",
    "\n",
    "import pandas as pd, numpy as np, tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f54952",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81564d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = get_normalized_data()\n",
    "\n",
    "X_train, y_train = train\n",
    "X_val, y_val = val\n",
    "X_test, y_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58b0ccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_train, tr_val, tr_test = get_normalized_transformed_data()\n",
    "\n",
    "tr_X_train, tr_y_train = tr_train\n",
    "tr_X_val, tr_y_val = tr_val\n",
    "tr_X_test, tr_y_test = tr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30b6902e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adam'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = HyperParameters()\n",
    "hp.Int('n_layers', min_value = 4, max_value = 15)\n",
    "hp.Int('n_units', min_value = 32, max_value = 512, step = 32)\n",
    "hp.Int('epochs', min_value = 50, max_value = 1000, step = 50)\n",
    "\n",
    "hp.Float('penalty', min_value = 1e-4, max_value = 1, sampling = 'log')\n",
    "\n",
    "hp.Choice('activation', ['relu', 'elu', 'softmax'])\n",
    "hp.Choice('optimizer', ['adam', 'rmsprop', 'adamax'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b33d4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_tuner(hp):\n",
    "    n_units = hp.get('n_units')\n",
    "    n_layers = hp.get('n_layers')\n",
    "    activation = hp.get('activation')\n",
    "    penalty = hp.get('penalty')\n",
    "    optimizer = hp.get('optimizer')\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(units = n_units, activation = activation, kernel_regularizer=l2(penalty), input_shape = (X_train.shape[1], )))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    for _ in range(n_layers):\n",
    "        model.add(tf.keras.layers.Dense(units = n_units, activation = activation, kernel_regularizer=l2(penalty)))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units = n_units, activation = activation, kernel_regularizer=l2(penalty)))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units = 1, activation = 'linear'))\n",
    "\n",
    "    model.compile(optimizer = optimizer, loss = mean_absolute_percentage_error)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebf823c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_units = 64, activation = 'elu', penalty = 0.00168, n_layers = 11, optimizer = 'rmsprop'):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(units = n_units, activation = activation, kernel_regularizer=l2(penalty), input_shape = (X_train.shape[1], )))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    for _ in range(n_layers):\n",
    "        model.add(tf.keras.layers.Dense(units = n_units, activation = activation, kernel_regularizer=l2(penalty)))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units = n_units, activation = activation, kernel_regularizer=l2(penalty)))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units = 1, activation = 'linear'))\n",
    "\n",
    "    model.compile(optimizer = optimizer, loss = mean_absolute_percentage_error)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21f9ba9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brynj\\Documents\\Mastersverkefni\\lokaverkefni_vel\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "148e7ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 9ms/step - loss: 37.3475 - val_loss: 9.0435\n",
      "Epoch 2/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 9.0413 - val_loss: 7.1171\n",
      "Epoch 3/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 6.7161 - val_loss: 5.9235\n",
      "Epoch 4/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.9780 - val_loss: 5.6703\n",
      "Epoch 5/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.7349 - val_loss: 5.7382\n",
      "Epoch 6/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.6208 - val_loss: 5.5901\n",
      "Epoch 7/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 5.5947 - val_loss: 5.5706\n",
      "Epoch 8/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 5.5195 - val_loss: 5.3812\n",
      "Epoch 9/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 5.4242 - val_loss: 5.8181\n",
      "Epoch 10/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 5.3931 - val_loss: 6.4059\n",
      "Epoch 11/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 5.3608 - val_loss: 5.7116\n",
      "Epoch 12/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 5.4160 - val_loss: 5.5707\n",
      "Epoch 13/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.3784 - val_loss: 5.3185\n",
      "Epoch 14/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 5.3806 - val_loss: 5.3884\n",
      "Epoch 15/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.3501 - val_loss: 5.4485\n",
      "Epoch 16/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 5.3424 - val_loss: 6.7596\n",
      "Epoch 17/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 5.3032 - val_loss: 5.1155\n",
      "Epoch 18/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 5.2878 - val_loss: 5.3968\n",
      "Epoch 19/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 5.2842 - val_loss: 5.4710\n",
      "Epoch 20/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 5.2762 - val_loss: 5.4068\n",
      "Epoch 21/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 5.2321 - val_loss: 6.2273\n",
      "Epoch 22/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 5.2790 - val_loss: 5.2001\n",
      "Epoch 23/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 5.2368 - val_loss: 5.2113\n",
      "Epoch 24/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 5.2278 - val_loss: 5.7419\n",
      "Epoch 25/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 5.2252 - val_loss: 5.6651\n",
      "Epoch 26/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 5.1951 - val_loss: 5.6208\n",
      "Epoch 27/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 5.2176 - val_loss: 5.0849\n",
      "Epoch 28/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 5.1831 - val_loss: 5.0634\n",
      "Epoch 29/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 5.1926 - val_loss: 5.2490\n",
      "Epoch 30/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 5.1896 - val_loss: 5.0868\n",
      "Epoch 31/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 5.2127 - val_loss: 5.3714\n",
      "Epoch 32/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 5.2027 - val_loss: 5.3009\n",
      "Epoch 33/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 5.2012 - val_loss: 9.4343\n",
      "Epoch 34/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 5.1988 - val_loss: 6.0838\n",
      "Epoch 35/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 5.2089 - val_loss: 5.2224\n",
      "Epoch 36/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.1756 - val_loss: 5.3172\n",
      "Epoch 37/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.2319 - val_loss: 5.5532\n",
      "Epoch 38/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.2122 - val_loss: 5.5154\n",
      "Epoch 39/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.1619 - val_loss: 5.1990\n",
      "Epoch 40/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.1927 - val_loss: 5.3641\n",
      "Epoch 41/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.2008 - val_loss: 5.0421\n",
      "Epoch 42/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.1641 - val_loss: 5.3611\n",
      "Epoch 43/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.1755 - val_loss: 6.0586\n",
      "Epoch 44/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.2206 - val_loss: 5.3411\n",
      "Epoch 45/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.1612 - val_loss: 5.2432\n",
      "Epoch 46/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.1545 - val_loss: 5.0985\n",
      "Epoch 47/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.1536 - val_loss: 5.2566\n",
      "Epoch 48/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.1541 - val_loss: 5.0877\n",
      "Epoch 49/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.0906 - val_loss: 5.0895\n",
      "Epoch 50/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.1656 - val_loss: 5.7549\n",
      "Epoch 51/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 5.1387 - val_loss: 5.6762\n",
      "Epoch 52/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1534 - val_loss: 5.1540\n",
      "Epoch 53/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1911 - val_loss: 5.1005\n",
      "Epoch 54/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1833 - val_loss: 5.0708\n",
      "Epoch 55/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1036 - val_loss: 5.0665\n",
      "Epoch 56/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1365 - val_loss: 5.0244\n",
      "Epoch 57/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1495 - val_loss: 5.0507\n",
      "Epoch 58/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1487 - val_loss: 5.0871\n",
      "Epoch 59/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1903 - val_loss: 5.9246\n",
      "Epoch 60/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1570 - val_loss: 5.1075\n",
      "Epoch 61/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1418 - val_loss: 5.1295\n",
      "Epoch 62/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1819 - val_loss: 5.2510\n",
      "Epoch 63/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1425 - val_loss: 5.3216\n",
      "Epoch 64/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1447 - val_loss: 5.1234\n",
      "Epoch 65/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1474 - val_loss: 5.2546\n",
      "Epoch 66/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1259 - val_loss: 5.8471\n",
      "Epoch 67/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1475 - val_loss: 6.7009\n",
      "Epoch 68/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1573 - val_loss: 5.5664\n",
      "Epoch 69/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1362 - val_loss: 5.9961\n",
      "Epoch 70/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1466 - val_loss: 6.2540\n",
      "Epoch 71/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1736 - val_loss: 4.9850\n",
      "Epoch 72/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1695 - val_loss: 5.1959\n",
      "Epoch 73/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1181 - val_loss: 5.0822\n",
      "Epoch 74/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1417 - val_loss: 5.1543\n",
      "Epoch 75/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1163 - val_loss: 5.1377\n",
      "Epoch 76/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1335 - val_loss: 5.4085\n",
      "Epoch 77/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1062 - val_loss: 5.2902\n",
      "Epoch 78/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1475 - val_loss: 5.4334\n",
      "Epoch 79/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1376 - val_loss: 5.1689\n",
      "Epoch 80/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1370 - val_loss: 5.0756\n",
      "Epoch 81/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1892 - val_loss: 5.6039\n",
      "Epoch 82/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1089 - val_loss: 5.7322\n",
      "Epoch 83/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1738 - val_loss: 5.1480\n",
      "Epoch 84/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1682 - val_loss: 5.1700\n",
      "Epoch 85/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1093 - val_loss: 5.7475\n",
      "Epoch 86/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1243 - val_loss: 5.8768\n",
      "Epoch 87/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1334 - val_loss: 5.3715\n",
      "Epoch 88/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1249 - val_loss: 5.6003\n",
      "Epoch 89/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1015 - val_loss: 5.3769\n",
      "Epoch 90/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1391 - val_loss: 6.5876\n",
      "Epoch 91/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1039 - val_loss: 5.3279\n",
      "Epoch 92/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1560 - val_loss: 6.4307\n",
      "Epoch 93/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1586 - val_loss: 5.0871\n",
      "Epoch 94/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1240 - val_loss: 5.1942\n",
      "Epoch 95/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1353 - val_loss: 5.8169\n",
      "Epoch 96/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1352 - val_loss: 5.3080\n",
      "Epoch 97/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1657 - val_loss: 5.7669\n",
      "Epoch 98/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1340 - val_loss: 5.0402\n",
      "Epoch 99/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0977 - val_loss: 5.8163\n",
      "Epoch 100/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1365 - val_loss: 5.3963\n",
      "Epoch 101/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 5.1439 - val_loss: 5.0339\n",
      "Epoch 102/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1227 - val_loss: 5.1179\n",
      "Epoch 103/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1071 - val_loss: 5.0291\n",
      "Epoch 104/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1479 - val_loss: 5.3272\n",
      "Epoch 105/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1252 - val_loss: 5.0731\n",
      "Epoch 106/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0910 - val_loss: 5.4869\n",
      "Epoch 107/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0972 - val_loss: 5.1590\n",
      "Epoch 108/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0953 - val_loss: 5.6107\n",
      "Epoch 109/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0844 - val_loss: 5.2189\n",
      "Epoch 110/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1399 - val_loss: 5.1097\n",
      "Epoch 111/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1020 - val_loss: 5.1189\n",
      "Epoch 112/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0901 - val_loss: 5.1080\n",
      "Epoch 113/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1261 - val_loss: 5.1084\n",
      "Epoch 114/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1138 - val_loss: 5.1724\n",
      "Epoch 115/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1414 - val_loss: 5.6566\n",
      "Epoch 116/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1477 - val_loss: 4.9301\n",
      "Epoch 117/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1056 - val_loss: 5.8467\n",
      "Epoch 118/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1423 - val_loss: 5.2754\n",
      "Epoch 119/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1230 - val_loss: 5.4424\n",
      "Epoch 120/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1061 - val_loss: 5.0505\n",
      "Epoch 121/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1364 - val_loss: 5.1227\n",
      "Epoch 122/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1399 - val_loss: 5.3694\n",
      "Epoch 123/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1425 - val_loss: 5.7340\n",
      "Epoch 124/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1002 - val_loss: 6.1069\n",
      "Epoch 125/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0992 - val_loss: 4.9405\n",
      "Epoch 126/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0920 - val_loss: 5.1533\n",
      "Epoch 127/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1241 - val_loss: 5.4771\n",
      "Epoch 128/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0979 - val_loss: 5.2830\n",
      "Epoch 129/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1247 - val_loss: 5.5846\n",
      "Epoch 130/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0926 - val_loss: 5.7188\n",
      "Epoch 131/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1117 - val_loss: 5.5142\n",
      "Epoch 132/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0900 - val_loss: 5.0873\n",
      "Epoch 133/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0868 - val_loss: 6.0671\n",
      "Epoch 134/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1187 - val_loss: 5.2278\n",
      "Epoch 135/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1182 - val_loss: 5.1103\n",
      "Epoch 136/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0513 - val_loss: 5.9626\n",
      "Epoch 137/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1407 - val_loss: 4.9142\n",
      "Epoch 138/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0417 - val_loss: 5.3100\n",
      "Epoch 139/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0891 - val_loss: 5.3688\n",
      "Epoch 140/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1636 - val_loss: 5.0020\n",
      "Epoch 141/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0879 - val_loss: 5.3208\n",
      "Epoch 142/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1401 - val_loss: 5.0190\n",
      "Epoch 143/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0832 - val_loss: 5.4910\n",
      "Epoch 144/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0770 - val_loss: 5.4245\n",
      "Epoch 145/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0745 - val_loss: 6.3306\n",
      "Epoch 146/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0976 - val_loss: 5.5802\n",
      "Epoch 147/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0976 - val_loss: 5.4736\n",
      "Epoch 148/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0789 - val_loss: 5.8705\n",
      "Epoch 149/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1337 - val_loss: 5.3634\n",
      "Epoch 150/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0897 - val_loss: 5.0962\n",
      "Epoch 151/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1337 - val_loss: 5.0028\n",
      "Epoch 152/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1741 - val_loss: 6.8408\n",
      "Epoch 153/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0844 - val_loss: 12.3559\n",
      "Epoch 154/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0832 - val_loss: 5.4421\n",
      "Epoch 155/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0925 - val_loss: 5.4406\n",
      "Epoch 156/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0655 - val_loss: 5.6393\n",
      "Epoch 157/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1254 - val_loss: 5.2492\n",
      "Epoch 158/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1310 - val_loss: 6.3679\n",
      "Epoch 159/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1357 - val_loss: 9.1568\n",
      "Epoch 160/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0906 - val_loss: 6.0700\n",
      "Epoch 161/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1088 - val_loss: 5.9463\n",
      "Epoch 162/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0852 - val_loss: 5.5863\n",
      "Epoch 163/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0678 - val_loss: 5.0702\n",
      "Epoch 164/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0841 - val_loss: 5.4986\n",
      "Epoch 165/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0772 - val_loss: 5.2366\n",
      "Epoch 166/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1767 - val_loss: 5.0640\n",
      "Epoch 167/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1146 - val_loss: 5.5425\n",
      "Epoch 168/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1160 - val_loss: 5.1760\n",
      "Epoch 169/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1535 - val_loss: 5.2127\n",
      "Epoch 170/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0981 - val_loss: 4.9748\n",
      "Epoch 171/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1211 - val_loss: 5.1628\n",
      "Epoch 172/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1070 - val_loss: 5.7546\n",
      "Epoch 173/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1087 - val_loss: 5.8187\n",
      "Epoch 174/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.1129 - val_loss: 6.3002\n",
      "Epoch 175/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1446 - val_loss: 5.1197\n",
      "Epoch 176/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0818 - val_loss: 5.0240\n",
      "Epoch 177/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0863 - val_loss: 5.3388\n",
      "Epoch 178/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0898 - val_loss: 4.9820\n",
      "Epoch 179/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0949 - val_loss: 5.2403\n",
      "Epoch 180/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0879 - val_loss: 5.6685\n",
      "Epoch 181/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1476 - val_loss: 12.3244\n",
      "Epoch 182/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0615 - val_loss: 5.3685\n",
      "Epoch 183/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.1181 - val_loss: 8.5185\n",
      "Epoch 184/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.1173 - val_loss: 5.6993\n",
      "Epoch 185/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.1216 - val_loss: 6.5261\n",
      "Epoch 186/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 5.1162 - val_loss: 10.5399\n",
      "Epoch 187/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0924 - val_loss: 8.3386\n",
      "Epoch 188/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1103 - val_loss: 6.8195\n",
      "Epoch 189/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1010 - val_loss: 5.4905\n",
      "Epoch 190/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0506 - val_loss: 5.4287\n",
      "Epoch 191/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0813 - val_loss: 5.1229\n",
      "Epoch 192/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1154 - val_loss: 5.3523\n",
      "Epoch 193/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0885 - val_loss: 5.7134\n",
      "Epoch 194/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1207 - val_loss: 5.3205\n",
      "Epoch 195/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.0718 - val_loss: 7.3731\n",
      "Epoch 196/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0663 - val_loss: 6.2764\n",
      "Epoch 197/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0848 - val_loss: 4.9358\n",
      "Epoch 198/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0889 - val_loss: 5.1533\n",
      "Epoch 199/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0930 - val_loss: 5.4732\n",
      "Epoch 200/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.0854 - val_loss: 6.3250\n",
      "Epoch 201/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.0865 - val_loss: 5.0776\n",
      "Epoch 202/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.0901 - val_loss: 5.0349\n",
      "Epoch 203/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0777 - val_loss: 5.2237\n",
      "Epoch 204/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0465 - val_loss: 4.9523\n",
      "Epoch 205/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1098 - val_loss: 5.2852\n",
      "Epoch 206/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.0930 - val_loss: 5.8994\n",
      "Epoch 207/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.1071 - val_loss: 5.0249\n",
      "Epoch 208/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 5.0771 - val_loss: 5.0484\n",
      "Epoch 209/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 5.0579 - val_loss: 5.0382\n",
      "Epoch 210/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.1152 - val_loss: 5.5473\n",
      "Epoch 211/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.0638 - val_loss: 5.2447\n",
      "Epoch 212/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0597 - val_loss: 5.5316\n",
      "Epoch 213/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.0960 - val_loss: 5.5955\n",
      "Epoch 214/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0598 - val_loss: 5.3490\n",
      "Epoch 215/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1306 - val_loss: 5.0824\n",
      "Epoch 216/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 5.0803 - val_loss: 5.6341\n",
      "Epoch 217/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0705 - val_loss: 5.4853\n",
      "Epoch 218/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0639 - val_loss: 5.1490\n",
      "Epoch 219/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1238 - val_loss: 5.7616\n",
      "Epoch 220/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1176 - val_loss: 5.0727\n",
      "Epoch 221/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0940 - val_loss: 5.7383\n",
      "Epoch 222/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1214 - val_loss: 5.5979\n",
      "Epoch 223/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0355 - val_loss: 5.4520\n",
      "Epoch 224/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0140 - val_loss: 5.1022\n",
      "Epoch 225/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0791 - val_loss: 4.9892\n",
      "Epoch 226/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0740 - val_loss: 4.9842\n",
      "Epoch 227/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1240 - val_loss: 5.2380\n",
      "Epoch 228/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0369 - val_loss: 5.0403\n",
      "Epoch 229/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1381 - val_loss: 6.2841\n",
      "Epoch 230/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1073 - val_loss: 5.6667\n",
      "Epoch 231/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0623 - val_loss: 5.5756\n",
      "Epoch 232/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0328 - val_loss: 6.3579\n",
      "Epoch 233/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0549 - val_loss: 5.4231\n",
      "Epoch 234/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0927 - val_loss: 5.5395\n",
      "Epoch 235/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0295 - val_loss: 5.5191\n",
      "Epoch 236/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0232 - val_loss: 5.1180\n",
      "Epoch 237/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0781 - val_loss: 5.5597\n",
      "Epoch 238/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0971 - val_loss: 9.2327\n",
      "Epoch 239/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0437 - val_loss: 5.0681\n",
      "Epoch 240/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1110 - val_loss: 6.4446\n",
      "Epoch 241/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0873 - val_loss: 8.3779\n",
      "Epoch 242/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0619 - val_loss: 6.5876\n",
      "Epoch 243/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0642 - val_loss: 6.0096\n",
      "Epoch 244/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0622 - val_loss: 5.0862\n",
      "Epoch 245/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0774 - val_loss: 5.2868\n",
      "Epoch 246/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1027 - val_loss: 5.6928\n",
      "Epoch 247/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1431 - val_loss: 5.3217\n",
      "Epoch 248/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0643 - val_loss: 6.2789\n",
      "Epoch 249/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0811 - val_loss: 6.7637\n",
      "Epoch 250/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1010 - val_loss: 8.0709\n",
      "Epoch 251/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0552 - val_loss: 5.1905\n",
      "Epoch 252/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0781 - val_loss: 5.5122\n",
      "Epoch 253/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1006 - val_loss: 5.0387\n",
      "Epoch 254/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0813 - val_loss: 5.1721\n",
      "Epoch 255/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0780 - val_loss: 5.7934\n",
      "Epoch 256/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0737 - val_loss: 6.0888\n",
      "Epoch 257/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0827 - val_loss: 6.5966\n",
      "Epoch 258/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0915 - val_loss: 5.7432\n",
      "Epoch 259/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1000 - val_loss: 5.4996\n",
      "Epoch 260/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0777 - val_loss: 5.2100\n",
      "Epoch 261/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0987 - val_loss: 5.7388\n",
      "Epoch 262/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0852 - val_loss: 5.0444\n",
      "Epoch 263/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0882 - val_loss: 5.8788\n",
      "Epoch 264/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0655 - val_loss: 6.4809\n",
      "Epoch 265/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1108 - val_loss: 5.9400\n",
      "Epoch 266/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0478 - val_loss: 5.9860\n",
      "Epoch 267/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1388 - val_loss: 6.4824\n",
      "Epoch 268/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0872 - val_loss: 6.8103\n",
      "Epoch 269/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0665 - val_loss: 6.8800\n",
      "Epoch 270/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1179 - val_loss: 5.4384\n",
      "Epoch 271/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1267 - val_loss: 4.9814\n",
      "Epoch 272/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0653 - val_loss: 7.8145\n",
      "Epoch 273/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1101 - val_loss: 6.2800\n",
      "Epoch 274/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0418 - val_loss: 6.6424\n",
      "Epoch 275/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0552 - val_loss: 6.5733\n",
      "Epoch 276/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0344 - val_loss: 5.0128\n",
      "Epoch 277/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 5.0624 - val_loss: 5.6458\n",
      "Epoch 278/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0914 - val_loss: 5.3337\n",
      "Epoch 279/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0662 - val_loss: 5.0959\n",
      "Epoch 280/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0863 - val_loss: 4.9922\n",
      "Epoch 281/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0786 - val_loss: 5.2597\n",
      "Epoch 282/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0798 - val_loss: 5.6474\n",
      "Epoch 283/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1308 - val_loss: 6.1540\n",
      "Epoch 284/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0696 - val_loss: 5.0992\n",
      "Epoch 285/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0980 - val_loss: 5.3841\n",
      "Epoch 286/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0811 - val_loss: 5.3793\n",
      "Epoch 287/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1008 - val_loss: 6.2238\n",
      "Epoch 288/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0344 - val_loss: 5.3621\n",
      "Epoch 289/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0541 - val_loss: 5.0750\n",
      "Epoch 290/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0709 - val_loss: 5.1158\n",
      "Epoch 291/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1231 - val_loss: 5.9269\n",
      "Epoch 292/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1995 - val_loss: 5.2141\n",
      "Epoch 293/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0638 - val_loss: 5.1366\n",
      "Epoch 294/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1232 - val_loss: 4.9921\n",
      "Epoch 295/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1334 - val_loss: 5.9079\n",
      "Epoch 296/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1216 - val_loss: 4.9914\n",
      "Epoch 297/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0902 - val_loss: 6.4522\n",
      "Epoch 298/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0941 - val_loss: 5.7872\n",
      "Epoch 299/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0753 - val_loss: 4.9849\n",
      "Epoch 300/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0414 - val_loss: 5.3925\n",
      "Epoch 301/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0746 - val_loss: 6.9711\n",
      "Epoch 302/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1012 - val_loss: 5.6943\n",
      "Epoch 303/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1111 - val_loss: 5.1972\n",
      "Epoch 304/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1066 - val_loss: 5.3895\n",
      "Epoch 305/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1086 - val_loss: 5.5176\n",
      "Epoch 306/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0836 - val_loss: 6.1773\n",
      "Epoch 307/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0492 - val_loss: 5.1910\n",
      "Epoch 308/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0736 - val_loss: 5.0534\n",
      "Epoch 309/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0694 - val_loss: 5.2186\n",
      "Epoch 310/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0807 - val_loss: 4.9470\n",
      "Epoch 311/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0467 - val_loss: 5.0116\n",
      "Epoch 312/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0318 - val_loss: 6.3992\n",
      "Epoch 313/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1564 - val_loss: 5.1550\n",
      "Epoch 314/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0317 - val_loss: 5.8238\n",
      "Epoch 315/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0406 - val_loss: 4.9600\n",
      "Epoch 316/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0452 - val_loss: 5.2314\n",
      "Epoch 317/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1106 - val_loss: 4.9108\n",
      "Epoch 318/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0954 - val_loss: 6.3200\n",
      "Epoch 319/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0312 - val_loss: 5.4458\n",
      "Epoch 320/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0727 - val_loss: 5.0737\n",
      "Epoch 321/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0995 - val_loss: 5.9574\n",
      "Epoch 322/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0599 - val_loss: 6.0792\n",
      "Epoch 323/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1055 - val_loss: 5.4044\n",
      "Epoch 324/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0946 - val_loss: 5.0248\n",
      "Epoch 325/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0436 - val_loss: 5.2215\n",
      "Epoch 326/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0837 - val_loss: 5.0984\n",
      "Epoch 327/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0222 - val_loss: 6.2852\n",
      "Epoch 328/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0492 - val_loss: 5.3804\n",
      "Epoch 329/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0829 - val_loss: 5.0223\n",
      "Epoch 330/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0922 - val_loss: 6.4810\n",
      "Epoch 331/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0908 - val_loss: 5.4581\n",
      "Epoch 332/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0735 - val_loss: 5.3697\n",
      "Epoch 333/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0605 - val_loss: 7.0595\n",
      "Epoch 334/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0418 - val_loss: 5.0802\n",
      "Epoch 335/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0638 - val_loss: 5.1052\n",
      "Epoch 336/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0734 - val_loss: 5.7272\n",
      "Epoch 337/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0943 - val_loss: 5.3006\n",
      "Epoch 338/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0930 - val_loss: 5.1301\n",
      "Epoch 339/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0848 - val_loss: 5.0417\n",
      "Epoch 340/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1008 - val_loss: 5.6566\n",
      "Epoch 341/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0956 - val_loss: 5.6724\n",
      "Epoch 342/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0425 - val_loss: 4.9672\n",
      "Epoch 343/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0746 - val_loss: 4.9593\n",
      "Epoch 344/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0671 - val_loss: 5.4555\n",
      "Epoch 345/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0928 - val_loss: 8.1725\n",
      "Epoch 346/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0835 - val_loss: 7.5795\n",
      "Epoch 347/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0696 - val_loss: 6.6367\n",
      "Epoch 348/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0868 - val_loss: 5.9425\n",
      "Epoch 349/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0630 - val_loss: 5.2055\n",
      "Epoch 350/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1062 - val_loss: 5.1017\n",
      "Epoch 351/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0337 - val_loss: 5.5030\n",
      "Epoch 352/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1029 - val_loss: 5.8297\n",
      "Epoch 353/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0559 - val_loss: 5.6020\n",
      "Epoch 354/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0250 - val_loss: 4.9340\n",
      "Epoch 355/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0336 - val_loss: 5.8866\n",
      "Epoch 356/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0551 - val_loss: 5.2158\n",
      "Epoch 357/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0804 - val_loss: 5.2249\n",
      "Epoch 358/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0924 - val_loss: 6.0810\n",
      "Epoch 359/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0054 - val_loss: 5.1129\n",
      "Epoch 360/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0678 - val_loss: 5.5712\n",
      "Epoch 361/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1181 - val_loss: 5.0792\n",
      "Epoch 362/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0845 - val_loss: 5.1950\n",
      "Epoch 363/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0338 - val_loss: 5.6241\n",
      "Epoch 364/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0886 - val_loss: 5.4532\n",
      "Epoch 365/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0453 - val_loss: 5.5539\n",
      "Epoch 366/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1426 - val_loss: 5.0164\n",
      "Epoch 367/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0410 - val_loss: 5.6306\n",
      "Epoch 368/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1338 - val_loss: 5.7953\n",
      "Epoch 369/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0863 - val_loss: 5.1975\n",
      "Epoch 370/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0820 - val_loss: 5.3464\n",
      "Epoch 371/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1025 - val_loss: 8.3999\n",
      "Epoch 372/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1426 - val_loss: 5.2631\n",
      "Epoch 373/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0565 - val_loss: 5.0159\n",
      "Epoch 374/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1467 - val_loss: 5.2113\n",
      "Epoch 375/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0794 - val_loss: 6.2658\n",
      "Epoch 376/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0778 - val_loss: 5.2561\n",
      "Epoch 377/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1047 - val_loss: 5.7988\n",
      "Epoch 378/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0957 - val_loss: 5.4837\n",
      "Epoch 379/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0505 - val_loss: 5.2056\n",
      "Epoch 380/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0867 - val_loss: 5.3200\n",
      "Epoch 381/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0520 - val_loss: 5.7690\n",
      "Epoch 382/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0587 - val_loss: 5.3159\n",
      "Epoch 383/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0933 - val_loss: 5.8311\n",
      "Epoch 384/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0699 - val_loss: 4.9543\n",
      "Epoch 385/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1481 - val_loss: 5.0757\n",
      "Epoch 386/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0861 - val_loss: 5.1363\n",
      "Epoch 387/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0780 - val_loss: 5.4459\n",
      "Epoch 388/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1145 - val_loss: 5.1531\n",
      "Epoch 389/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0756 - val_loss: 5.2818\n",
      "Epoch 390/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0292 - val_loss: 6.3622\n",
      "Epoch 391/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0856 - val_loss: 4.9927\n",
      "Epoch 392/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0182 - val_loss: 6.1683\n",
      "Epoch 393/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1270 - val_loss: 5.2734\n",
      "Epoch 394/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0948 - val_loss: 4.9883\n",
      "Epoch 395/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0708 - val_loss: 5.2312\n",
      "Epoch 396/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0907 - val_loss: 5.2558\n",
      "Epoch 397/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0911 - val_loss: 5.0512\n",
      "Epoch 398/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0161 - val_loss: 5.4801\n",
      "Epoch 399/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1167 - val_loss: 4.9729\n",
      "Epoch 400/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0815 - val_loss: 5.2239\n",
      "Epoch 401/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0739 - val_loss: 4.9328\n",
      "Epoch 402/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0968 - val_loss: 16.7759\n",
      "Epoch 403/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.2404 - val_loss: 5.2695\n",
      "Epoch 404/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0770 - val_loss: 6.2850\n",
      "Epoch 405/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0680 - val_loss: 5.9122\n",
      "Epoch 406/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0975 - val_loss: 4.9561\n",
      "Epoch 407/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0829 - val_loss: 6.1548\n",
      "Epoch 408/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0713 - val_loss: 5.6808\n",
      "Epoch 409/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0742 - val_loss: 5.5055\n",
      "Epoch 410/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0631 - val_loss: 5.9704\n",
      "Epoch 411/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0952 - val_loss: 7.2878\n",
      "Epoch 412/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0608 - val_loss: 6.2805\n",
      "Epoch 413/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0577 - val_loss: 5.3128\n",
      "Epoch 414/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0815 - val_loss: 7.4020\n",
      "Epoch 415/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0078 - val_loss: 5.0148\n",
      "Epoch 416/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1174 - val_loss: 5.0846\n",
      "Epoch 417/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0805 - val_loss: 5.4240\n",
      "Epoch 418/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0286 - val_loss: 4.9613\n",
      "Epoch 419/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1035 - val_loss: 5.9152\n",
      "Epoch 420/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 5.0676 - val_loss: 6.6081\n",
      "Epoch 421/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0783 - val_loss: 5.0680\n",
      "Epoch 422/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0659 - val_loss: 4.9658\n",
      "Epoch 423/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1092 - val_loss: 5.5949\n",
      "Epoch 424/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0541 - val_loss: 5.6600\n",
      "Epoch 425/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0655 - val_loss: 8.8538\n",
      "Epoch 426/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1006 - val_loss: 5.0090\n",
      "Epoch 427/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0688 - val_loss: 4.9283\n",
      "Epoch 428/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1053 - val_loss: 5.2405\n",
      "Epoch 429/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0930 - val_loss: 6.2284\n",
      "Epoch 430/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0795 - val_loss: 5.1244\n",
      "Epoch 431/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1253 - val_loss: 6.1207\n",
      "Epoch 432/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0770 - val_loss: 5.5020\n",
      "Epoch 433/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0664 - val_loss: 5.4588\n",
      "Epoch 434/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0282 - val_loss: 5.3122\n",
      "Epoch 435/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0371 - val_loss: 5.1771\n",
      "Epoch 436/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0978 - val_loss: 5.2356\n",
      "Epoch 437/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0999 - val_loss: 4.9494\n",
      "Epoch 438/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0361 - val_loss: 5.3987\n",
      "Epoch 439/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0460 - val_loss: 4.9950\n",
      "Epoch 440/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0621 - val_loss: 6.3416\n",
      "Epoch 441/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0195 - val_loss: 5.9892\n",
      "Epoch 442/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0476 - val_loss: 5.1476\n",
      "Epoch 443/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0375 - val_loss: 5.1496\n",
      "Epoch 444/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1002 - val_loss: 5.3107\n",
      "Epoch 445/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0278 - val_loss: 4.9496\n",
      "Epoch 446/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0615 - val_loss: 5.6227\n",
      "Epoch 447/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0950 - val_loss: 5.0177\n",
      "Epoch 448/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0888 - val_loss: 6.7167\n",
      "Epoch 449/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0304 - val_loss: 6.3043\n",
      "Epoch 450/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0143 - val_loss: 5.3449\n",
      "Epoch 451/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0531 - val_loss: 5.3499\n",
      "Epoch 452/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0839 - val_loss: 5.0293\n",
      "Epoch 453/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0288 - val_loss: 5.5632\n",
      "Epoch 454/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0429 - val_loss: 5.4444\n",
      "Epoch 455/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0872 - val_loss: 4.9955\n",
      "Epoch 456/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0526 - val_loss: 5.9625\n",
      "Epoch 457/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0314 - val_loss: 5.7147\n",
      "Epoch 458/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0267 - val_loss: 5.7160\n",
      "Epoch 459/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0411 - val_loss: 6.9116\n",
      "Epoch 460/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0633 - val_loss: 5.3712\n",
      "Epoch 461/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0599 - val_loss: 5.6597\n",
      "Epoch 462/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0332 - val_loss: 5.9001\n",
      "Epoch 463/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0551 - val_loss: 10.7099\n",
      "Epoch 464/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0599 - val_loss: 5.2101\n",
      "Epoch 465/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1625 - val_loss: 5.6569\n",
      "Epoch 466/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1007 - val_loss: 4.8913\n",
      "Epoch 467/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0340 - val_loss: 6.2059\n",
      "Epoch 468/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1133 - val_loss: 6.4344\n",
      "Epoch 469/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1270 - val_loss: 4.9167\n",
      "Epoch 470/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0658 - val_loss: 5.1328\n",
      "Epoch 471/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0692 - val_loss: 5.4703\n",
      "Epoch 472/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0687 - val_loss: 5.3715\n",
      "Epoch 473/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0802 - val_loss: 7.1276\n",
      "Epoch 474/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0960 - val_loss: 5.4648\n",
      "Epoch 475/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0819 - val_loss: 6.4310\n",
      "Epoch 476/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0563 - val_loss: 5.2090\n",
      "Epoch 477/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0507 - val_loss: 5.0373\n",
      "Epoch 478/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0472 - val_loss: 5.1102\n",
      "Epoch 479/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0721 - val_loss: 5.5681\n",
      "Epoch 480/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0374 - val_loss: 5.4577\n",
      "Epoch 481/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0915 - val_loss: 4.9514\n",
      "Epoch 482/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0734 - val_loss: 5.0951\n",
      "Epoch 483/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0484 - val_loss: 5.3964\n",
      "Epoch 484/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0287 - val_loss: 5.6537\n",
      "Epoch 485/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0312 - val_loss: 5.3384\n",
      "Epoch 486/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1010 - val_loss: 5.0668\n",
      "Epoch 487/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0514 - val_loss: 5.0030\n",
      "Epoch 488/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0458 - val_loss: 6.1463\n",
      "Epoch 489/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1027 - val_loss: 5.8251\n",
      "Epoch 490/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0308 - val_loss: 6.5446\n",
      "Epoch 491/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1132 - val_loss: 5.2225\n",
      "Epoch 492/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0222 - val_loss: 5.2771\n",
      "Epoch 493/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1190 - val_loss: 4.9815\n",
      "Epoch 494/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0742 - val_loss: 5.8013\n",
      "Epoch 495/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0689 - val_loss: 5.3706\n",
      "Epoch 496/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0355 - val_loss: 5.0202\n",
      "Epoch 497/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0313 - val_loss: 5.5772\n",
      "Epoch 498/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0367 - val_loss: 7.6613\n",
      "Epoch 499/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0650 - val_loss: 4.9969\n",
      "Epoch 500/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0404 - val_loss: 4.9880\n",
      "Epoch 501/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0726 - val_loss: 5.4953\n",
      "Epoch 502/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0162 - val_loss: 5.2568\n",
      "Epoch 503/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0783 - val_loss: 5.5069\n",
      "Epoch 504/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0714 - val_loss: 5.0960\n",
      "Epoch 505/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0689 - val_loss: 6.9699\n",
      "Epoch 506/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0655 - val_loss: 5.7852\n",
      "Epoch 507/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.2057 - val_loss: 5.0173\n",
      "Epoch 508/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0187 - val_loss: 5.0863\n",
      "Epoch 509/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0492 - val_loss: 5.5535\n",
      "Epoch 510/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.1015 - val_loss: 5.7312\n",
      "Epoch 511/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0198 - val_loss: 5.9531\n",
      "Epoch 512/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0646 - val_loss: 5.4761\n",
      "Epoch 513/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0691 - val_loss: 5.1782\n",
      "Epoch 514/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0502 - val_loss: 6.8172\n",
      "Epoch 515/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0841 - val_loss: 5.6756\n",
      "Epoch 516/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0464 - val_loss: 5.2199\n",
      "Epoch 517/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0912 - val_loss: 5.4142\n",
      "Epoch 518/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0675 - val_loss: 5.2084\n",
      "Epoch 519/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0996 - val_loss: 5.2692\n",
      "Epoch 520/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0904 - val_loss: 5.0936\n",
      "Epoch 521/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0447 - val_loss: 5.2588\n",
      "Epoch 522/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0158 - val_loss: 5.2494\n",
      "Epoch 523/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0348 - val_loss: 5.6240\n",
      "Epoch 524/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0440 - val_loss: 4.8917\n",
      "Epoch 525/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0845 - val_loss: 5.6169\n",
      "Epoch 526/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0782 - val_loss: 5.1732\n",
      "Epoch 527/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0820 - val_loss: 4.9972\n",
      "Epoch 528/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0305 - val_loss: 5.7983\n",
      "Epoch 529/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0296 - val_loss: 5.2179\n",
      "Epoch 530/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0944 - val_loss: 5.2517\n",
      "Epoch 531/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0686 - val_loss: 5.0625\n",
      "Epoch 532/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0717 - val_loss: 6.0830\n",
      "Epoch 533/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0774 - val_loss: 4.9109\n",
      "Epoch 534/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0465 - val_loss: 5.9760\n",
      "Epoch 535/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0998 - val_loss: 5.0054\n",
      "Epoch 536/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0526 - val_loss: 5.2327\n",
      "Epoch 537/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0751 - val_loss: 5.0472\n",
      "Epoch 538/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0769 - val_loss: 5.6507\n",
      "Epoch 539/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0660 - val_loss: 5.0182\n",
      "Epoch 540/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0436 - val_loss: 5.3683\n",
      "Epoch 541/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0201 - val_loss: 6.2158\n",
      "Epoch 542/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0440 - val_loss: 5.8359\n",
      "Epoch 543/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0451 - val_loss: 5.1577\n",
      "Epoch 544/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0995 - val_loss: 6.1250\n",
      "Epoch 545/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0706 - val_loss: 5.5867\n",
      "Epoch 546/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0373 - val_loss: 5.1617\n",
      "Epoch 547/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0635 - val_loss: 5.5924\n",
      "Epoch 548/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0705 - val_loss: 5.2470\n",
      "Epoch 549/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0393 - val_loss: 5.7569\n",
      "Epoch 550/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0587 - val_loss: 5.1957\n",
      "Epoch 551/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0627 - val_loss: 5.3042\n",
      "Epoch 552/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0699 - val_loss: 5.0496\n",
      "Epoch 553/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0943 - val_loss: 5.5097\n",
      "Epoch 554/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0589 - val_loss: 5.3471\n",
      "Epoch 555/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0879 - val_loss: 5.1926\n",
      "Epoch 556/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 4.9753 - val_loss: 5.3870\n",
      "Epoch 557/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0468 - val_loss: 10.8576\n",
      "Epoch 558/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0326 - val_loss: 5.1039\n",
      "Epoch 559/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0454 - val_loss: 5.2379\n",
      "Epoch 560/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0795 - val_loss: 5.3500\n",
      "Epoch 561/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0720 - val_loss: 6.2640\n",
      "Epoch 562/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0636 - val_loss: 5.1488\n",
      "Epoch 563/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0588 - val_loss: 5.6950\n",
      "Epoch 564/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1178 - val_loss: 5.0733\n",
      "Epoch 565/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1018 - val_loss: 5.3261\n",
      "Epoch 566/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0801 - val_loss: 6.4724\n",
      "Epoch 567/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0585 - val_loss: 5.7193\n",
      "Epoch 568/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0108 - val_loss: 5.0802\n",
      "Epoch 569/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0844 - val_loss: 5.0633\n",
      "Epoch 570/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0733 - val_loss: 5.3352\n",
      "Epoch 571/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0579 - val_loss: 4.9694\n",
      "Epoch 572/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0435 - val_loss: 5.6574\n",
      "Epoch 573/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0779 - val_loss: 5.7110\n",
      "Epoch 574/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0738 - val_loss: 5.0840\n",
      "Epoch 575/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0719 - val_loss: 5.0743\n",
      "Epoch 576/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0635 - val_loss: 8.3202\n",
      "Epoch 577/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1198 - val_loss: 6.9617\n",
      "Epoch 578/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0633 - val_loss: 5.0220\n",
      "Epoch 579/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0399 - val_loss: 5.3084\n",
      "Epoch 580/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0712 - val_loss: 5.0535\n",
      "Epoch 581/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0598 - val_loss: 4.9795\n",
      "Epoch 582/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0436 - val_loss: 5.6857\n",
      "Epoch 583/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0483 - val_loss: 4.9736\n",
      "Epoch 584/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0303 - val_loss: 5.5949\n",
      "Epoch 585/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0813 - val_loss: 5.5562\n",
      "Epoch 586/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 5.0747 - val_loss: 6.0514\n",
      "Epoch 587/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1089 - val_loss: 6.3092\n",
      "Epoch 588/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0787 - val_loss: 5.6906\n",
      "Epoch 589/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0385 - val_loss: 5.3109\n",
      "Epoch 590/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0736 - val_loss: 5.1165\n",
      "Epoch 591/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1018 - val_loss: 5.1128\n",
      "Epoch 592/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.2582 - val_loss: 5.0005\n",
      "Epoch 593/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0747 - val_loss: 5.7255\n",
      "Epoch 594/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0428 - val_loss: 5.7518\n",
      "Epoch 595/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0577 - val_loss: 5.5813\n",
      "Epoch 596/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0416 - val_loss: 5.0449\n",
      "Epoch 597/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0692 - val_loss: 5.5779\n",
      "Epoch 598/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0162 - val_loss: 4.9901\n",
      "Epoch 599/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0838 - val_loss: 7.7652\n",
      "Epoch 600/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0786 - val_loss: 6.2000\n",
      "Epoch 601/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1000 - val_loss: 5.3756\n",
      "Epoch 602/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0599 - val_loss: 5.0464\n",
      "Epoch 603/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0656 - val_loss: 5.2939\n",
      "Epoch 604/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0799 - val_loss: 5.5542\n",
      "Epoch 605/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1046 - val_loss: 5.7764\n",
      "Epoch 606/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0465 - val_loss: 4.9954\n",
      "Epoch 607/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0745 - val_loss: 5.3019\n",
      "Epoch 608/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0605 - val_loss: 5.0771\n",
      "Epoch 609/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0528 - val_loss: 4.9669\n",
      "Epoch 610/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1567 - val_loss: 7.0824\n",
      "Epoch 611/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0244 - val_loss: 5.9953\n",
      "Epoch 612/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1040 - val_loss: 5.0243\n",
      "Epoch 613/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0881 - val_loss: 6.9844\n",
      "Epoch 614/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0586 - val_loss: 5.6917\n",
      "Epoch 615/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0695 - val_loss: 5.5429\n",
      "Epoch 616/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0354 - val_loss: 5.1918\n",
      "Epoch 617/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0862 - val_loss: 4.8923\n",
      "Epoch 618/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0885 - val_loss: 4.9939\n",
      "Epoch 619/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1019 - val_loss: 5.1733\n",
      "Epoch 620/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0405 - val_loss: 5.0397\n",
      "Epoch 621/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0512 - val_loss: 6.8104\n",
      "Epoch 622/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0429 - val_loss: 5.0096\n",
      "Epoch 623/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0773 - val_loss: 5.1109\n",
      "Epoch 624/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0683 - val_loss: 5.0483\n",
      "Epoch 625/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.0958 - val_loss: 5.2120\n",
      "Epoch 626/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1172 - val_loss: 5.2749\n",
      "Epoch 627/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1092 - val_loss: 5.7407\n",
      "Epoch 628/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0753 - val_loss: 6.2815\n",
      "Epoch 629/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0958 - val_loss: 5.2506\n",
      "Epoch 630/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0686 - val_loss: 5.1175\n",
      "Epoch 631/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0868 - val_loss: 5.3365\n",
      "Epoch 632/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0567 - val_loss: 4.9728\n",
      "Epoch 633/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1979 - val_loss: 5.8910\n",
      "Epoch 634/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1605 - val_loss: 5.0137\n",
      "Epoch 635/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0886 - val_loss: 5.3837\n",
      "Epoch 636/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0255 - val_loss: 4.8842\n",
      "Epoch 637/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0258 - val_loss: 5.1006\n",
      "Epoch 638/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0607 - val_loss: 5.1823\n",
      "Epoch 639/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1217 - val_loss: 5.8444\n",
      "Epoch 640/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0766 - val_loss: 6.1057\n",
      "Epoch 641/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0387 - val_loss: 5.3278\n",
      "Epoch 642/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0424 - val_loss: 5.2002\n",
      "Epoch 643/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0182 - val_loss: 6.1964\n",
      "Epoch 644/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0856 - val_loss: 5.5149\n",
      "Epoch 645/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0321 - val_loss: 5.2474\n",
      "Epoch 646/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0574 - val_loss: 5.3441\n",
      "Epoch 647/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0954 - val_loss: 11.0303\n",
      "Epoch 648/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0678 - val_loss: 5.1270\n",
      "Epoch 649/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0324 - val_loss: 5.4106\n",
      "Epoch 650/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0388 - val_loss: 5.9434\n",
      "Epoch 651/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0682 - val_loss: 5.9863\n",
      "Epoch 652/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1170 - val_loss: 5.4983\n",
      "Epoch 653/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0545 - val_loss: 8.1214\n",
      "Epoch 654/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0819 - val_loss: 5.2943\n",
      "Epoch 655/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0223 - val_loss: 5.1865\n",
      "Epoch 656/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0422 - val_loss: 5.3966\n",
      "Epoch 657/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0936 - val_loss: 4.9255\n",
      "Epoch 658/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0862 - val_loss: 5.0338\n",
      "Epoch 659/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0896 - val_loss: 5.7546\n",
      "Epoch 660/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0304 - val_loss: 5.1777\n",
      "Epoch 661/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0696 - val_loss: 7.4113\n",
      "Epoch 662/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0293 - val_loss: 5.0022\n",
      "Epoch 663/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0805 - val_loss: 5.9169\n",
      "Epoch 664/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0535 - val_loss: 5.9650\n",
      "Epoch 665/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0376 - val_loss: 5.5966\n",
      "Epoch 666/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0444 - val_loss: 5.5605\n",
      "Epoch 667/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0804 - val_loss: 5.4086\n",
      "Epoch 668/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0343 - val_loss: 5.2568\n",
      "Epoch 669/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0987 - val_loss: 6.0045\n",
      "Epoch 670/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1262 - val_loss: 5.3590\n",
      "Epoch 671/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1386 - val_loss: 5.6350\n",
      "Epoch 672/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0310 - val_loss: 5.7107\n",
      "Epoch 673/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0838 - val_loss: 4.9301\n",
      "Epoch 674/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1383 - val_loss: 5.4618\n",
      "Epoch 675/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0643 - val_loss: 5.9667\n",
      "Epoch 676/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1017 - val_loss: 5.2893\n",
      "Epoch 677/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0186 - val_loss: 4.8909\n",
      "Epoch 678/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1035 - val_loss: 4.9562\n",
      "Epoch 679/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0677 - val_loss: 5.5296\n",
      "Epoch 680/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0551 - val_loss: 5.4504\n",
      "Epoch 681/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0563 - val_loss: 5.3233\n",
      "Epoch 682/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0541 - val_loss: 7.0261\n",
      "Epoch 683/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0636 - val_loss: 5.3222\n",
      "Epoch 684/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0845 - val_loss: 5.2084\n",
      "Epoch 685/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1011 - val_loss: 8.3441\n",
      "Epoch 686/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1421 - val_loss: 5.3042\n",
      "Epoch 687/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0633 - val_loss: 6.1596\n",
      "Epoch 688/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1627 - val_loss: 5.4685\n",
      "Epoch 689/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0968 - val_loss: 7.0782\n",
      "Epoch 690/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0677 - val_loss: 5.4952\n",
      "Epoch 691/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0771 - val_loss: 8.8919\n",
      "Epoch 692/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0733 - val_loss: 5.0117\n",
      "Epoch 693/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0446 - val_loss: 5.3496\n",
      "Epoch 694/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.1014 - val_loss: 5.5934\n",
      "Epoch 695/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0486 - val_loss: 4.9496\n",
      "Epoch 696/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0658 - val_loss: 4.9347\n",
      "Epoch 697/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0178 - val_loss: 8.3989\n",
      "Epoch 698/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0545 - val_loss: 5.3625\n",
      "Epoch 699/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0419 - val_loss: 5.1059\n",
      "Epoch 700/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0533 - val_loss: 4.9475\n",
      "Epoch 701/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0706 - val_loss: 7.1719\n",
      "Epoch 702/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0532 - val_loss: 5.3510\n",
      "Epoch 703/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0426 - val_loss: 5.0027\n",
      "Epoch 704/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0952 - val_loss: 5.1078\n",
      "Epoch 705/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0971 - val_loss: 5.4810\n",
      "Epoch 706/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0607 - val_loss: 10.0787\n",
      "Epoch 707/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0799 - val_loss: 5.3056\n",
      "Epoch 708/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 4.9699 - val_loss: 4.9856\n",
      "Epoch 709/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0138 - val_loss: 5.3371\n",
      "Epoch 710/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0616 - val_loss: 5.8860\n",
      "Epoch 711/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0571 - val_loss: 5.2789\n",
      "Epoch 712/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0486 - val_loss: 5.6876\n",
      "Epoch 713/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0137 - val_loss: 6.0912\n",
      "Epoch 714/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0160 - val_loss: 5.8895\n",
      "Epoch 715/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1108 - val_loss: 5.0619\n",
      "Epoch 716/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0961 - val_loss: 5.3731\n",
      "Epoch 717/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0599 - val_loss: 5.1212\n",
      "Epoch 718/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0364 - val_loss: 5.1482\n",
      "Epoch 719/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0527 - val_loss: 5.3565\n",
      "Epoch 720/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0691 - val_loss: 5.5495\n",
      "Epoch 721/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0338 - val_loss: 8.4028\n",
      "Epoch 722/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0868 - val_loss: 5.2656\n",
      "Epoch 723/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1095 - val_loss: 5.5381\n",
      "Epoch 724/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1037 - val_loss: 7.7571\n",
      "Epoch 725/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1225 - val_loss: 4.9311\n",
      "Epoch 726/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0422 - val_loss: 5.9782\n",
      "Epoch 727/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1014 - val_loss: 4.9825\n",
      "Epoch 728/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0327 - val_loss: 5.3683\n",
      "Epoch 729/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.1127 - val_loss: 5.2195\n",
      "Epoch 730/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0665 - val_loss: 5.2820\n",
      "Epoch 731/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0510 - val_loss: 7.2518\n",
      "Epoch 732/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0973 - val_loss: 5.8841\n",
      "Epoch 733/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0909 - val_loss: 6.0924\n",
      "Epoch 734/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0593 - val_loss: 5.7128\n",
      "Epoch 735/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 5.0912 - val_loss: 5.2151\n",
      "Epoch 736/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 5.0679 - val_loss: 5.7309\n",
      "Epoch 737/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 5.0474 - val_loss: 5.8765\n",
      "Epoch 738/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0690 - val_loss: 5.0485\n",
      "Epoch 739/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1038 - val_loss: 5.0690\n",
      "Epoch 740/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0561 - val_loss: 6.2161\n",
      "Epoch 741/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.1342 - val_loss: 4.9135\n",
      "Epoch 742/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0288 - val_loss: 6.0079\n",
      "Epoch 743/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0568 - val_loss: 5.0113\n",
      "Epoch 744/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0665 - val_loss: 7.7634\n",
      "Epoch 745/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0626 - val_loss: 7.0622\n",
      "Epoch 746/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0468 - val_loss: 5.5271\n",
      "Epoch 747/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0816 - val_loss: 6.0349\n",
      "Epoch 748/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0620 - val_loss: 5.0136\n",
      "Epoch 749/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0409 - val_loss: 5.8401\n",
      "Epoch 750/750\n",
      "\u001b[1m1254/1254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5.0462 - val_loss: 5.0123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a4277de240>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 750, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81949fc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "masker cannot be None.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(X_test)\n\u001b[0;32m      4\u001b[0m shap\u001b[38;5;241m.\u001b[39msummary_plot(shap_values, X_test, plot_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\brynj\\Documents\\Mastersverkefni\\lokaverkefni_vel\\.venv\\Lib\\site-packages\\shap\\explainers\\_explainer.py:182\u001b[0m, in \u001b[0;36mExplainer.__init__\u001b[1;34m(self, model, masker, link, algorithm, output_names, feature_names, linearize_link, seed, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpermutation\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m=\u001b[39m explainers\u001b[38;5;241m.\u001b[39mPermutationExplainer\n\u001b[1;32m--> 182\u001b[0m     \u001b[43mexplainers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPermutationExplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinearize_link\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinearize_link\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartition\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m=\u001b[39m explainers\u001b[38;5;241m.\u001b[39mPartitionExplainer\n",
      "File \u001b[1;32mc:\\Users\\brynj\\Documents\\Mastersverkefni\\lokaverkefni_vel\\.venv\\Lib\\site-packages\\shap\\explainers\\_permutation.py:50\u001b[0m, in \u001b[0;36mPermutationExplainer.__init__\u001b[1;34m(self, model, masker, link, feature_names, linearize_link, seed, **call_args)\u001b[0m\n\u001b[0;32m     47\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m masker \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmasker cannot be None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model, masker, link\u001b[38;5;241m=\u001b[39mlink, linearize_link\u001b[38;5;241m=\u001b[39mlinearize_link, feature_names\u001b[38;5;241m=\u001b[39mfeature_names)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, Model):\n",
      "\u001b[1;31mValueError\u001b[0m: masker cannot be None."
     ]
    }
   ],
   "source": [
    "import shap\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5d2a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [01h 10m 34s]\n",
      "val_loss: 5.550853729248047\n",
      "\n",
      "Best val_loss So Far: 4.785363674163818\n",
      "Total elapsed time: 1d 05h 27m 19s\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "# Define the TensorBoard callback\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "tuner = Hyperband(build_model_tuner, hyperparameters = hp, objective = 'val_loss', max_epochs = 100, project_name = \"Try-2024-4-30\")\n",
    "tuner.search(X_train, y_train, validation_data = (X_val, y_val), callbacks = [tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29fcd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, sys\n",
    "stdout_buffer = io.StringIO()\n",
    "sys.stdout = stdout_buffer\n",
    "tuner.results_summary(num_trials = -1)\n",
    "sys.stdout = sys.__stdout__\n",
    "trials = stdout_buffer.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09536494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_cast(value):\n",
    "    if value.isdigit():\n",
    "        return int(value)\n",
    "    try:\n",
    "        return float(value)\n",
    "    except:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7eed4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_layers</th>\n",
       "      <th>n_units</th>\n",
       "      <th>epochs</th>\n",
       "      <th>penalty</th>\n",
       "      <th>activation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>650</td>\n",
       "      <td>0.698985</td>\n",
       "      <td>softmax</td>\n",
       "      <td>adamax</td>\n",
       "      <td>6.229276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>288</td>\n",
       "      <td>350</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>relu</td>\n",
       "      <td>adamax</td>\n",
       "      <td>51.318115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>700</td>\n",
       "      <td>0.090532</td>\n",
       "      <td>elu</td>\n",
       "      <td>adamax</td>\n",
       "      <td>38.406048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>160</td>\n",
       "      <td>750</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>elu</td>\n",
       "      <td>adam</td>\n",
       "      <td>7.252502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>448</td>\n",
       "      <td>700</td>\n",
       "      <td>0.015770</td>\n",
       "      <td>softmax</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>6.214997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>9</td>\n",
       "      <td>256</td>\n",
       "      <td>250</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>5.129033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>150</td>\n",
       "      <td>0.437092</td>\n",
       "      <td>softmax</td>\n",
       "      <td>adamax</td>\n",
       "      <td>6.183726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>9</td>\n",
       "      <td>160</td>\n",
       "      <td>950</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>elu</td>\n",
       "      <td>adam</td>\n",
       "      <td>4.908710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>9</td>\n",
       "      <td>256</td>\n",
       "      <td>400</td>\n",
       "      <td>0.008343</td>\n",
       "      <td>softmax</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>6.183403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>13</td>\n",
       "      <td>480</td>\n",
       "      <td>350</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>elu</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>5.550854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_layers  n_units  epochs   penalty activation optimizer      score\n",
       "trial                                                                     \n",
       "0            12      128     650  0.698985    softmax    adamax   6.229276\n",
       "1            10      288     350  0.014159       relu    adamax  51.318115\n",
       "2            12       32     700  0.090532        elu    adamax  38.406048\n",
       "3            15      160     750  0.000682        elu      adam   7.252502\n",
       "4             6      448     700  0.015770    softmax   rmsprop   6.214997\n",
       "...         ...      ...     ...       ...        ...       ...        ...\n",
       "249           9      256     250  0.005325       relu      adam   5.129033\n",
       "250           4      160     150  0.437092    softmax    adamax   6.183726\n",
       "251           9      160     950  0.000322        elu      adam   4.908710\n",
       "252           9      256     400  0.008343    softmax   rmsprop   6.183403\n",
       "253          13      480     350  0.011433        elu   rmsprop   5.550854\n",
       "\n",
       "[253 rows x 7 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials_list = [item.split('\\n') for item in trials.split('\\n\\n')]\n",
    "columns  = ['trial', 'n_layers', 'n_units', 'epochs', 'penalty', 'activation', 'optimizer', 'score']\n",
    "data = []\n",
    "for trial in trials_list[1:]:\n",
    "    data.append([safe_cast(trial[i].split()[1]) for i in [0, 2, 3, 4, 5, 6, 7, 12]])\n",
    "df = pd.DataFrame(data, columns = columns)\n",
    "df = df.set_index('trial')\n",
    "df = df.sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1fa9d699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Results summary',\n",
       "  'Results in .\\\\Try-2024-4-30',\n",
       "  'Showing -1 best trials',\n",
       "  'Objective(name=\"val_loss\", direction=\"min\")'],\n",
       " ['Trial 0208 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 64',\n",
       "  'epochs: 750',\n",
       "  'penalty: 0.00016805497508728002',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 100',\n",
       "  'tuner/initial_epoch: 34',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 3',\n",
       "  'tuner/trial_id: 0203',\n",
       "  'Score: 4.785363674163818'],\n",
       " ['Trial 0209 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 32',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.0011634242577526809',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 100',\n",
       "  'tuner/initial_epoch: 34',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 3',\n",
       "  'tuner/trial_id: 0205',\n",
       "  'Score: 4.799617290496826'],\n",
       " ['Trial 0234 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 32',\n",
       "  'epochs: 550',\n",
       "  'penalty: 0.00012403080548890148',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 100',\n",
       "  'tuner/initial_epoch: 34',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0228',\n",
       "  'Score: 4.847485065460205'],\n",
       " ['Trial 0147 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 32',\n",
       "  'epochs: 500',\n",
       "  'penalty: 0.0004522597863974099',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 100',\n",
       "  'tuner/initial_epoch: 34',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 4',\n",
       "  'tuner/trial_id: 0142',\n",
       "  'Score: 4.865616321563721'],\n",
       " ['Trial 0146 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 160',\n",
       "  'epochs: 350',\n",
       "  'penalty: 0.00045334479290571315',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 100',\n",
       "  'tuner/initial_epoch: 34',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 4',\n",
       "  'tuner/trial_id: 0143',\n",
       "  'Score: 4.875845909118652'],\n",
       " ['Trial 0203 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 64',\n",
       "  'epochs: 750',\n",
       "  'penalty: 0.00016805497508728002',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 12',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0193',\n",
       "  'Score: 4.905960559844971'],\n",
       " ['Trial 0251 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 160',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.00032224554240753575',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 100',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 0',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 4.908709526062012'],\n",
       " ['Trial 0246 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 352',\n",
       "  'epochs: 700',\n",
       "  'penalty: 0.0007030499224653095',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 100',\n",
       "  'tuner/initial_epoch: 34',\n",
       "  'tuner/bracket: 1',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0239',\n",
       "  'Score: 4.951113700866699'],\n",
       " ['Trial 0143 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 160',\n",
       "  'epochs: 350',\n",
       "  'penalty: 0.00045334479290571315',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 12',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 3',\n",
       "  'tuner/trial_id: 0137',\n",
       "  'Score: 4.982942581176758'],\n",
       " ['Trial 0142 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 32',\n",
       "  'epochs: 500',\n",
       "  'penalty: 0.0004522597863974099',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 12',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 3',\n",
       "  'tuner/trial_id: 0131',\n",
       "  'Score: 4.9889936447143555'],\n",
       " ['Trial 0245 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 6',\n",
       "  'n_units: 320',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.0020118434365960936',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 100',\n",
       "  'tuner/initial_epoch: 34',\n",
       "  'tuner/bracket: 1',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0238',\n",
       "  'Score: 4.993835926055908'],\n",
       " ['Trial 0205 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 32',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.0011634242577526809',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 12',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0191',\n",
       "  'Score: 5.000128746032715'],\n",
       " ['Trial 0235 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 128',\n",
       "  'epochs: 350',\n",
       "  'penalty: 0.006040501553960593',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 100',\n",
       "  'tuner/initial_epoch: 34',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0231',\n",
       "  'Score: 5.075009346008301'],\n",
       " ['Trial 0204 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 32',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.0015098634036420837',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 12',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0190',\n",
       "  'Score: 5.088324546813965'],\n",
       " ['Trial 0193 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 64',\n",
       "  'epochs: 750',\n",
       "  'penalty: 0.00016805497508728002',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0166',\n",
       "  'Score: 5.0883259773254395'],\n",
       " ['Trial 0238 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 6',\n",
       "  'n_units: 320',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.0020118434365960936',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 1',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 5.093811511993408'],\n",
       " ['Trial 0131 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 32',\n",
       "  'epochs: 500',\n",
       "  'penalty: 0.0004522597863974099',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0098',\n",
       "  'Score: 5.104008197784424'],\n",
       " ['Trial 0190 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 32',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.0015098634036420837',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0177',\n",
       "  'Score: 5.111949920654297'],\n",
       " ['Trial 0249 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 256',\n",
       "  'epochs: 250',\n",
       "  'penalty: 0.005324509405848477',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 100',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 0',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 5.129033088684082'],\n",
       " ['Trial 0228 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 32',\n",
       "  'epochs: 550',\n",
       "  'penalty: 0.00012403080548890148',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 12',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0226',\n",
       "  'Score: 5.129417419433594'],\n",
       " ['Trial 0206 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 32',\n",
       "  'epochs: 850',\n",
       "  'penalty: 0.0029144281916149255',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 12',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0192',\n",
       "  'Score: 5.137323379516602'],\n",
       " ['Trial 0191 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 32',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.0011634242577526809',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0151',\n",
       "  'Score: 5.231006145477295'],\n",
       " ['Trial 0231 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 128',\n",
       "  'epochs: 350',\n",
       "  'penalty: 0.006040501553960593',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 12',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0223',\n",
       "  'Score: 5.233858108520508'],\n",
       " ['Trial 0248 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 448',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.030412613929163',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 100',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 0',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 5.287631034851074'],\n",
       " ['Trial 0230 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 512',\n",
       "  'epochs: 500',\n",
       "  'penalty: 0.0015958133456440437',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 12',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0218',\n",
       "  'Score: 5.322508335113525'],\n",
       " ['Trial 0192 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 32',\n",
       "  'epochs: 850',\n",
       "  'penalty: 0.0029144281916149255',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0156',\n",
       "  'Score: 5.336890697479248'],\n",
       " ['Trial 0137 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 160',\n",
       "  'epochs: 350',\n",
       "  'penalty: 0.00045334479290571315',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0108',\n",
       "  'Score: 5.351766586303711'],\n",
       " ['Trial 0098 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 32',\n",
       "  'epochs: 500',\n",
       "  'penalty: 0.0004522597863974099',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0078',\n",
       "  'Score: 5.382173538208008'],\n",
       " ['Trial 0207 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 32',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.09616241581104543',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 12',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0189',\n",
       "  'Score: 5.401946544647217'],\n",
       " ['Trial 0229 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 7',\n",
       "  'n_units: 480',\n",
       "  'epochs: 100',\n",
       "  'penalty: 0.04683021125130215',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 12',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0211',\n",
       "  'Score: 5.4053730964660645'],\n",
       " ['Trial 0189 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 32',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.09616241581104543',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0175',\n",
       "  'Score: 5.416514873504639'],\n",
       " ['Trial 0226 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 32',\n",
       "  'epochs: 550',\n",
       "  'penalty: 0.00012403080548890148',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 5.482943534851074'],\n",
       " ['Trial 0239 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 352',\n",
       "  'epochs: 700',\n",
       "  'penalty: 0.0007030499224653095',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 1',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 5.517719745635986'],\n",
       " ['Trial 0232 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 256',\n",
       "  'epochs: 1000',\n",
       "  'penalty: 0.2141470614184636',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 12',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0213',\n",
       "  'Score: 5.519038677215576'],\n",
       " ['Trial 0253 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 13',\n",
       "  'n_units: 480',\n",
       "  'epochs: 350',\n",
       "  'penalty: 0.011433450960650536',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 100',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 0',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 5.550853729248047'],\n",
       " ['Trial 0175 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 32',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.09616241581104543',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 5.576959133148193'],\n",
       " ['Trial 0196 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 32',\n",
       "  'epochs: 850',\n",
       "  'penalty: 0.6384250503855154',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0181',\n",
       "  'Score: 5.631555080413818'],\n",
       " ['Trial 0177 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 32',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.0015098634036420837',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 5.633463382720947'],\n",
       " ['Trial 0194 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 128',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.001596757226564531',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0182',\n",
       "  'Score: 5.679262638092041'],\n",
       " ['Trial 0195 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 256',\n",
       "  'epochs: 200',\n",
       "  'penalty: 0.09018774637960088',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0180',\n",
       "  'Score: 5.732332706451416'],\n",
       " ['Trial 0211 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 7',\n",
       "  'n_units: 480',\n",
       "  'epochs: 100',\n",
       "  'penalty: 0.04683021125130215',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 5.733368396759033'],\n",
       " ['Trial 0151 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 32',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.0011634242577526809',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 5.749381065368652'],\n",
       " ['Trial 0218 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 512',\n",
       "  'epochs: 500',\n",
       "  'penalty: 0.0015958133456440437',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 5.880391597747803'],\n",
       " ['Trial 0156 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 32',\n",
       "  'epochs: 850',\n",
       "  'penalty: 0.0029144281916149255',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 5.894123554229736'],\n",
       " ['Trial 0166 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 64',\n",
       "  'epochs: 750',\n",
       "  'penalty: 0.00016805497508728002',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 5.915963172912598'],\n",
       " ['Trial 0078 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 32',\n",
       "  'epochs: 500',\n",
       "  'penalty: 0.0004522597863974099',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 5.957390785217285'],\n",
       " ['Trial 0223 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 128',\n",
       "  'epochs: 350',\n",
       "  'penalty: 0.006040501553960593',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 5.962034225463867'],\n",
       " ['Trial 0182 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 128',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.001596757226564531',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 5.966073989868164'],\n",
       " ['Trial 0180 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 256',\n",
       "  'epochs: 200',\n",
       "  'penalty: 0.09018774637960088',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.009378433227539'],\n",
       " ['Trial 0213 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 256',\n",
       "  'epochs: 1000',\n",
       "  'penalty: 0.2141470614184636',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.16019344329834'],\n",
       " ['Trial 0181 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 32',\n",
       "  'epochs: 850',\n",
       "  'penalty: 0.6384250503855154',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.176681995391846'],\n",
       " ['Trial 0244 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 8',\n",
       "  'n_units: 352',\n",
       "  'epochs: 250',\n",
       "  'penalty: 0.08337798629030718',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 1',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.183396816253662'],\n",
       " ['Trial 0144 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 320',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.057612641474795716',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 12',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 3',\n",
       "  'tuner/trial_id: 0134',\n",
       "  'Score: 6.183399677276611'],\n",
       " ['Trial 0247 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 8',\n",
       "  'n_units: 352',\n",
       "  'epochs: 250',\n",
       "  'penalty: 0.08337798629030718',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 100',\n",
       "  'tuner/initial_epoch: 34',\n",
       "  'tuner/bracket: 1',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0244',\n",
       "  'Score: 6.183403015136719'],\n",
       " ['Trial 0252 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 256',\n",
       "  'epochs: 400',\n",
       "  'penalty: 0.008343369701389994',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 100',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 0',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.183403015136719'],\n",
       " ['Trial 0145 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 320',\n",
       "  'epochs: 500',\n",
       "  'penalty: 0.019689049605609892',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 12',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 3',\n",
       "  'tuner/trial_id: 0138',\n",
       "  'Score: 6.183413505554199'],\n",
       " ['Trial 0134 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 320',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.057612641474795716',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0102',\n",
       "  'Score: 6.1834540367126465'],\n",
       " ['Trial 0236 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 384',\n",
       "  'epochs: 450',\n",
       "  'penalty: 0.007899011733482932',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 1',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.183462142944336'],\n",
       " ['Trial 0138 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 320',\n",
       "  'epochs: 500',\n",
       "  'penalty: 0.019689049605609892',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0099',\n",
       "  'Score: 6.183495044708252'],\n",
       " ['Trial 0132 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 6',\n",
       "  'n_units: 448',\n",
       "  'epochs: 700',\n",
       "  'penalty: 0.015770198961887326',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0103',\n",
       "  'Score: 6.183521270751953'],\n",
       " ['Trial 0233 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 320',\n",
       "  'epochs: 50',\n",
       "  'penalty: 0.00718994494873152',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 12',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0220',\n",
       "  'Score: 6.183627128601074'],\n",
       " ['Trial 0250 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 160',\n",
       "  'epochs: 150',\n",
       "  'penalty: 0.43709246835931953',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 100',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 0',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.183725833892822'],\n",
       " ['Trial 0136 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 352',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.020348187723896512',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0120',\n",
       "  'Score: 6.18380069732666'],\n",
       " ['Trial 0199 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 352',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.0319343151390217',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0150',\n",
       "  'Score: 6.1839213371276855'],\n",
       " ['Trial 0237 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 288',\n",
       "  'epochs: 50',\n",
       "  'penalty: 0.004363225090876433',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 1',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.183953285217285'],\n",
       " ['Trial 0103 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 6',\n",
       "  'n_units: 448',\n",
       "  'epochs: 700',\n",
       "  'penalty: 0.015770198961887326',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0004',\n",
       "  'Score: 6.184186935424805'],\n",
       " ['Trial 0220 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 320',\n",
       "  'epochs: 50',\n",
       "  'penalty: 0.00718994494873152',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.184189796447754'],\n",
       " ['Trial 0241 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 384',\n",
       "  'epochs: 100',\n",
       "  'penalty: 0.0003933578568657208',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 1',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.184295177459717'],\n",
       " ['Trial 0141 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 288',\n",
       "  'epochs: 150',\n",
       "  'penalty: 0.0021618087793637357',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0100',\n",
       "  'Score: 6.185091972351074'],\n",
       " ['Trial 0139 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 8',\n",
       "  'n_units: 32',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.42700202676163146',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0116',\n",
       "  'Score: 6.18544340133667'],\n",
       " ['Trial 0243 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 448',\n",
       "  'epochs: 450',\n",
       "  'penalty: 0.08660236074430706',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 1',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.185550689697266'],\n",
       " ['Trial 0109 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 416',\n",
       "  'epochs: 550',\n",
       "  'penalty: 0.05812363894576088',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0022',\n",
       "  'Score: 6.185609817504883'],\n",
       " ['Trial 0133 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 416',\n",
       "  'epochs: 550',\n",
       "  'penalty: 0.05812363894576088',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0109',\n",
       "  'Score: 6.185921669006348'],\n",
       " ['Trial 0135 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 480',\n",
       "  'epochs: 750',\n",
       "  'penalty: 0.00414308713557036',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0122',\n",
       "  'Score: 6.186347961425781'],\n",
       " ['Trial 0219 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 8',\n",
       "  'n_units: 64',\n",
       "  'epochs: 450',\n",
       "  'penalty: 0.3169216769261721',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.1863603591918945'],\n",
       " ['Trial 0242 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 13',\n",
       "  'n_units: 64',\n",
       "  'epochs: 550',\n",
       "  'penalty: 0.00019329790663662191',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 1',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.1871018409729'],\n",
       " ['Trial 0197 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 352',\n",
       "  'epochs: 800',\n",
       "  'penalty: 0.0005574780229448393',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0185',\n",
       "  'Score: 6.187166690826416'],\n",
       " ['Trial 0102 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 320',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.057612641474795716',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0032',\n",
       "  'Score: 6.18856143951416'],\n",
       " ['Trial 0198 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 96',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.08001463100771879',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0167',\n",
       "  'Score: 6.188823699951172'],\n",
       " ['Trial 0202 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 192',\n",
       "  'epochs: 100',\n",
       "  'penalty: 0.15355924776545524',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0169',\n",
       "  'Score: 6.188851356506348'],\n",
       " ['Trial 0122 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 480',\n",
       "  'epochs: 750',\n",
       "  'penalty: 0.00414308713557036',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0023',\n",
       "  'Score: 6.189448833465576'],\n",
       " ['Trial 0140 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 384',\n",
       "  'epochs: 50',\n",
       "  'penalty: 0.1074660936454146',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 2',\n",
       "  'tuner/trial_id: 0110',\n",
       "  'Score: 6.189549446105957'],\n",
       " ['Trial 0120 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 352',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.020348187723896512',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0045',\n",
       "  'Score: 6.189691066741943'],\n",
       " ['Trial 0019 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 320',\n",
       "  'epochs: 500',\n",
       "  'penalty: 0.019689049605609892',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.1909356117248535'],\n",
       " ['Trial 0200 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 7',\n",
       "  'n_units: 480',\n",
       "  'epochs: 750',\n",
       "  'penalty: 0.09936062298299556',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0158',\n",
       "  'Score: 6.1918511390686035'],\n",
       " ['Trial 0108 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 160',\n",
       "  'epochs: 350',\n",
       "  'penalty: 0.00045334479290571315',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0080',\n",
       "  'Score: 6.192023754119873'],\n",
       " ['Trial 0212 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 160',\n",
       "  'epochs: 300',\n",
       "  'penalty: 0.3412201943829172',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.192896366119385'],\n",
       " ['Trial 0099 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 320',\n",
       "  'epochs: 500',\n",
       "  'penalty: 0.019689049605609892',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0019',\n",
       "  'Score: 6.194195747375488'],\n",
       " ['Trial 0201 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 64',\n",
       "  'epochs: 450',\n",
       "  'penalty: 0.7981517417756686',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 4',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0178',\n",
       "  'Score: 6.196014404296875'],\n",
       " ['Trial 0116 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 8',\n",
       "  'n_units: 32',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.42700202676163146',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0041',\n",
       "  'Score: 6.196361064910889'],\n",
       " ['Trial 0110 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 384',\n",
       "  'epochs: 50',\n",
       "  'penalty: 0.1074660936454146',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0013',\n",
       "  'Score: 6.197202205657959'],\n",
       " ['Trial 0100 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 288',\n",
       "  'epochs: 150',\n",
       "  'penalty: 0.0021618087793637357',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0064',\n",
       "  'Score: 6.197248458862305'],\n",
       " ['Trial 0064 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 288',\n",
       "  'epochs: 150',\n",
       "  'penalty: 0.0021618087793637357',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.198619842529297'],\n",
       " ['Trial 0185 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 352',\n",
       "  'epochs: 800',\n",
       "  'penalty: 0.0005574780229448393',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.198873519897461'],\n",
       " ['Trial 0167 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 96',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.08001463100771879',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.201875686645508'],\n",
       " ['Trial 0106 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 128',\n",
       "  'epochs: 300',\n",
       "  'penalty: 0.0001191243478551459',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0036',\n",
       "  'Score: 6.203962326049805'],\n",
       " ['Trial 0111 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 384',\n",
       "  'epochs: 250',\n",
       "  'penalty: 0.18850524270748606',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0070',\n",
       "  'Score: 6.204407215118408'],\n",
       " ['Trial 0113 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 128',\n",
       "  'epochs: 300',\n",
       "  'penalty: 0.0015114441230745328',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0093',\n",
       "  'Score: 6.205173969268799'],\n",
       " ['Trial 0094 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 288',\n",
       "  'epochs: 150',\n",
       "  'penalty: 0.00019655855660299468',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.205889701843262'],\n",
       " ['Trial 0032 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 320',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.057612641474795716',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.206889629364014'],\n",
       " ['Trial 0150 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 352',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.0319343151390217',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.207028388977051'],\n",
       " ['Trial 0101 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 288',\n",
       "  'epochs: 150',\n",
       "  'penalty: 0.00019655855660299468',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0094',\n",
       "  'Score: 6.208313941955566'],\n",
       " ['Trial 0121 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 96',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.048303815238729404',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0037',\n",
       "  'Score: 6.210061073303223'],\n",
       " ['Trial 0158 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 7',\n",
       "  'n_units: 480',\n",
       "  'epochs: 750',\n",
       "  'penalty: 0.09936062298299556',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.21025276184082'],\n",
       " ['Trial 0124 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 64',\n",
       "  'epochs: 600',\n",
       "  'penalty: 0.02551628170513271',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0086',\n",
       "  'Score: 6.210896968841553'],\n",
       " ['Trial 0004 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 6',\n",
       "  'n_units: 448',\n",
       "  'epochs: 700',\n",
       "  'penalty: 0.015770198961887326',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.214997291564941'],\n",
       " ['Trial 0178 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 64',\n",
       "  'epochs: 450',\n",
       "  'penalty: 0.7981517417756686',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.215530872344971'],\n",
       " ['Trial 0105 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 480',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.05334052586410296',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0021',\n",
       "  'Score: 6.217638969421387'],\n",
       " ['Trial 0130 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 96',\n",
       "  'epochs: 250',\n",
       "  'penalty: 0.014923984179913191',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0083',\n",
       "  'Score: 6.2180280685424805'],\n",
       " ['Trial 0169 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 192',\n",
       "  'epochs: 100',\n",
       "  'penalty: 0.15355924776545524',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.218062400817871'],\n",
       " ['Trial 0049 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 96',\n",
       "  'epochs: 850',\n",
       "  'penalty: 0.0019951347434735717',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.218448638916016'],\n",
       " ['Trial 0021 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 480',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.05334052586410296',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.223819255828857'],\n",
       " ['Trial 0104 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 96',\n",
       "  'epochs: 850',\n",
       "  'penalty: 0.0019951347434735717',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0049',\n",
       "  'Score: 6.223931312561035'],\n",
       " ['Trial 0152 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 6',\n",
       "  'n_units: 160',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.30790847246594627',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.226435661315918'],\n",
       " ['Trial 0215 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 6',\n",
       "  'n_units: 288',\n",
       "  'epochs: 150',\n",
       "  'penalty: 0.20875682692884862',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.226672172546387'],\n",
       " ['Trial 0036 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 128',\n",
       "  'epochs: 300',\n",
       "  'penalty: 0.0001191243478551459',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.229022979736328'],\n",
       " ['Trial 0000 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 128',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.6989845492013856',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.229275703430176'],\n",
       " ['Trial 0174 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 416',\n",
       "  'epochs: 850',\n",
       "  'penalty: 0.2683697336323167',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.231243133544922'],\n",
       " ['Trial 0080 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 160',\n",
       "  'epochs: 350',\n",
       "  'penalty: 0.00045334479290571315',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.234068393707275'],\n",
       " ['Trial 0112 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 384',\n",
       "  'epochs: 850',\n",
       "  'penalty: 0.4280850015285197',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0016',\n",
       "  'Score: 6.235053539276123'],\n",
       " ['Trial 0022 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 416',\n",
       "  'epochs: 550',\n",
       "  'penalty: 0.05812363894576088',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.236045837402344'],\n",
       " ['Trial 0115 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 256',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.00021678615702562285',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0089',\n",
       "  'Score: 6.237119197845459'],\n",
       " ['Trial 0013 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 384',\n",
       "  'epochs: 50',\n",
       "  'penalty: 0.1074660936454146',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.238428592681885'],\n",
       " ['Trial 0070 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 384',\n",
       "  'epochs: 250',\n",
       "  'penalty: 0.18850524270748606',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.240459442138672'],\n",
       " ['Trial 0016 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 384',\n",
       "  'epochs: 850',\n",
       "  'penalty: 0.4280850015285197',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.242220878601074'],\n",
       " ['Trial 0107 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 128',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.6989845492013856',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0000',\n",
       "  'Score: 6.24534273147583'],\n",
       " ['Trial 0126 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 352',\n",
       "  'epochs: 150',\n",
       "  'penalty: 0.0004078755228796164',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0031',\n",
       "  'Score: 6.247287750244141'],\n",
       " ['Trial 0093 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 128',\n",
       "  'epochs: 300',\n",
       "  'penalty: 0.0015114441230745328',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.247980117797852'],\n",
       " ['Trial 0035 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 64',\n",
       "  'epochs: 550',\n",
       "  'penalty: 0.7323439334703346',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.251304626464844'],\n",
       " ['Trial 0172 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 6',\n",
       "  'n_units: 448',\n",
       "  'epochs: 300',\n",
       "  'penalty: 0.00016230765719921455',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.260103225708008'],\n",
       " ['Trial 0123 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 256',\n",
       "  'epochs: 200',\n",
       "  'penalty: 0.7043825105201087',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0066',\n",
       "  'Score: 6.261671543121338'],\n",
       " ['Trial 0119 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 64',\n",
       "  'epochs: 400',\n",
       "  'penalty: 0.00039692357604820293',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0076',\n",
       "  'Score: 6.262840270996094'],\n",
       " ['Trial 0114 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 64',\n",
       "  'epochs: 550',\n",
       "  'penalty: 0.7323439334703346',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0035',\n",
       "  'Score: 6.270798206329346'],\n",
       " ['Trial 0225 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 448',\n",
       "  'epochs: 750',\n",
       "  'penalty: 0.291387168409349',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.271028518676758'],\n",
       " ['Trial 0089 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 256',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.00021678615702562285',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.27482271194458'],\n",
       " ['Trial 0117 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 8',\n",
       "  'n_units: 96',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.3589879741698836',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0008',\n",
       "  'Score: 6.27590274810791'],\n",
       " ['Trial 0118 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 192',\n",
       "  'epochs: 400',\n",
       "  'penalty: 0.4928114224631008',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0040',\n",
       "  'Score: 6.277817726135254'],\n",
       " ['Trial 0041 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 8',\n",
       "  'n_units: 32',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.42700202676163146',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.278306484222412'],\n",
       " ['Trial 0008 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 8',\n",
       "  'n_units: 96',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.3589879741698836',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.287035942077637'],\n",
       " ['Trial 0129 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 64',\n",
       "  'epochs: 50',\n",
       "  'penalty: 0.11539388445410814',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0055',\n",
       "  'Score: 6.310031890869141'],\n",
       " ['Trial 0040 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 192',\n",
       "  'epochs: 400',\n",
       "  'penalty: 0.4928114224631008',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.314513683319092'],\n",
       " ['Trial 0125 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 128',\n",
       "  'epochs: 400',\n",
       "  'penalty: 0.0026549339678613297',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0052',\n",
       "  'Score: 6.320004940032959'],\n",
       " ['Trial 0076 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 64',\n",
       "  'epochs: 400',\n",
       "  'penalty: 0.00039692357604820293',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.322234153747559'],\n",
       " ['Trial 0240 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 512',\n",
       "  'epochs: 450',\n",
       "  'penalty: 0.1405810083263659',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 34',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 1',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.341679573059082'],\n",
       " ['Trial 0045 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 352',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.020348187723896512',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.343428134918213'],\n",
       " ['Trial 0037 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 96',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.048303815238729404',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.346235752105713'],\n",
       " ['Trial 0127 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 320',\n",
       "  'epochs: 50',\n",
       "  'penalty: 0.4631330172169124',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0020',\n",
       "  'Score: 6.372701168060303'],\n",
       " ['Trial 0023 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 480',\n",
       "  'epochs: 750',\n",
       "  'penalty: 0.00414308713557036',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.387735843658447'],\n",
       " ['Trial 0066 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 256',\n",
       "  'epochs: 200',\n",
       "  'penalty: 0.7043825105201087',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.389568328857422'],\n",
       " ['Trial 0086 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 64',\n",
       "  'epochs: 600',\n",
       "  'penalty: 0.02551628170513271',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.389604091644287'],\n",
       " ['Trial 0052 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 128',\n",
       "  'epochs: 400',\n",
       "  'penalty: 0.0026549339678613297',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.393857955932617'],\n",
       " ['Trial 0031 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 352',\n",
       "  'epochs: 150',\n",
       "  'penalty: 0.0004078755228796164',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.395763397216797'],\n",
       " ['Trial 0128 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 6',\n",
       "  'n_units: 352',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.504927607210697',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 2',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 1',\n",
       "  'tuner/trial_id: 0053',\n",
       "  'Score: 6.399882793426514'],\n",
       " ['Trial 0171 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 320',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.5157869619299722',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.443378448486328'],\n",
       " ['Trial 0020 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 320',\n",
       "  'epochs: 50',\n",
       "  'penalty: 0.4631330172169124',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.455789089202881'],\n",
       " ['Trial 0053 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 6',\n",
       "  'n_units: 352',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.504927607210697',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.465066432952881'],\n",
       " ['Trial 0055 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 64',\n",
       "  'epochs: 50',\n",
       "  'penalty: 0.11539388445410814',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.53367280960083'],\n",
       " ['Trial 0083 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 96',\n",
       "  'epochs: 250',\n",
       "  'penalty: 0.014923984179913191',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.587595462799072'],\n",
       " ['Trial 0091 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 96',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.004082024335437871',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.597958564758301'],\n",
       " ['Trial 0061 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 256',\n",
       "  'epochs: 200',\n",
       "  'penalty: 0.010022528321422017',\n",
       "  'activation: softmax',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.602982997894287'],\n",
       " ['Trial 0221 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 288',\n",
       "  'epochs: 450',\n",
       "  'penalty: 0.04279068409270781',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.603349208831787'],\n",
       " ['Trial 0075 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 320',\n",
       "  'epochs: 850',\n",
       "  'penalty: 0.9676273094715058',\n",
       "  'activation: softmax',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.6814284324646'],\n",
       " ['Trial 0082 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 96',\n",
       "  'epochs: 250',\n",
       "  'penalty: 0.00013856023829265365',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.692066192626953'],\n",
       " ['Trial 0161 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 6',\n",
       "  'n_units: 512',\n",
       "  'epochs: 750',\n",
       "  'penalty: 0.08255164809713317',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.707897663116455'],\n",
       " ['Trial 0017 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 448',\n",
       "  'epochs: 350',\n",
       "  'penalty: 0.0001641073925293833',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.7097649574279785'],\n",
       " ['Trial 0210 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 416',\n",
       "  'epochs: 200',\n",
       "  'penalty: 0.11899264997203639',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.7904052734375'],\n",
       " ['Trial 0216 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 7',\n",
       "  'n_units: 512',\n",
       "  'epochs: 850',\n",
       "  'penalty: 0.44125537582029906',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.796512603759766'],\n",
       " ['Trial 0173 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 224',\n",
       "  'epochs: 100',\n",
       "  'penalty: 0.005296136254083728',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.839207172393799'],\n",
       " ['Trial 0058 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 384',\n",
       "  'epochs: 750',\n",
       "  'penalty: 0.9223533568643021',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.874177932739258'],\n",
       " ['Trial 0054 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 6',\n",
       "  'n_units: 320',\n",
       "  'epochs: 300',\n",
       "  'penalty: 0.01612811137242038',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.889404773712158'],\n",
       " ['Trial 0164 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 13',\n",
       "  'n_units: 512',\n",
       "  'epochs: 450',\n",
       "  'penalty: 0.8971610835014443',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.956468105316162'],\n",
       " ['Trial 0168 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 480',\n",
       "  'epochs: 600',\n",
       "  'penalty: 0.0001335402244557769',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 6.961031913757324'],\n",
       " ['Trial 0048 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 352',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.49763387145253496',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.058620929718018'],\n",
       " ['Trial 0224 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 480',\n",
       "  'epochs: 750',\n",
       "  'penalty: 0.00024334435840655104',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.09412145614624'],\n",
       " ['Trial 0176 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 480',\n",
       "  'epochs: 300',\n",
       "  'penalty: 0.0001071099431776204',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.129549980163574'],\n",
       " ['Trial 0187 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 192',\n",
       "  'epochs: 250',\n",
       "  'penalty: 0.11666794747276085',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.203622341156006'],\n",
       " ['Trial 0003 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 160',\n",
       "  'epochs: 750',\n",
       "  'penalty: 0.0006821574460146837',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.252501964569092'],\n",
       " ['Trial 0006 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 224',\n",
       "  'epochs: 450',\n",
       "  'penalty: 0.00025633580489738616',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.3542938232421875'],\n",
       " ['Trial 0072 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 448',\n",
       "  'epochs: 300',\n",
       "  'penalty: 0.45545425020814484',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.377309799194336'],\n",
       " ['Trial 0030 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 320',\n",
       "  'epochs: 50',\n",
       "  'penalty: 0.00011942922405315138',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.399264335632324'],\n",
       " ['Trial 0227 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 480',\n",
       "  'epochs: 100',\n",
       "  'penalty: 0.0017442878344527135',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.529101848602295'],\n",
       " ['Trial 0046 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 224',\n",
       "  'epochs: 350',\n",
       "  'penalty: 0.0004947485933185408',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.537998676300049'],\n",
       " ['Trial 0039 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 448',\n",
       "  'epochs: 350',\n",
       "  'penalty: 0.0002681630388870722',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.616400718688965'],\n",
       " ['Trial 0160 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 256',\n",
       "  'epochs: 700',\n",
       "  'penalty: 0.0002550680814925858',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.660253524780273'],\n",
       " ['Trial 0044 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 32',\n",
       "  'epochs: 300',\n",
       "  'penalty: 0.008511163646183758',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.7315993309021'],\n",
       " ['Trial 0060 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 448',\n",
       "  'epochs: 600',\n",
       "  'penalty: 0.00011878372837729476',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.783569812774658'],\n",
       " ['Trial 0222 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 13',\n",
       "  'n_units: 416',\n",
       "  'epochs: 200',\n",
       "  'penalty: 0.3910455538063891',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.784937858581543'],\n",
       " ['Trial 0018 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 6',\n",
       "  'n_units: 64',\n",
       "  'epochs: 700',\n",
       "  'penalty: 0.018402758353325104',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.887731075286865'],\n",
       " ['Trial 0059 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 480',\n",
       "  'epochs: 500',\n",
       "  'penalty: 0.0005034124031546577',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 7.913009166717529'],\n",
       " ['Trial 0154 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 96',\n",
       "  'epochs: 400',\n",
       "  'penalty: 0.0022956715628954212',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 8.151365280151367'],\n",
       " ['Trial 0009 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 5',\n",
       "  'n_units: 128',\n",
       "  'epochs: 850',\n",
       "  'penalty: 0.0030094274847113087',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 8.16873550415039'],\n",
       " ['Trial 0163 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 224',\n",
       "  'epochs: 250',\n",
       "  'penalty: 0.002108212923321126',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 8.283822059631348'],\n",
       " ['Trial 0090 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 288',\n",
       "  'epochs: 300',\n",
       "  'penalty: 0.00031338084110645145',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 8.331260681152344'],\n",
       " ['Trial 0183 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 384',\n",
       "  'epochs: 450',\n",
       "  'penalty: 0.19803961287796815',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 8.5056734085083'],\n",
       " ['Trial 0155 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 352',\n",
       "  'epochs: 250',\n",
       "  'penalty: 0.07942744414174627',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 8.60887622833252'],\n",
       " ['Trial 0214 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 448',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.0064771017982135845',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 8.799581527709961'],\n",
       " ['Trial 0153 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 64',\n",
       "  'epochs: 750',\n",
       "  'penalty: 0.296039896809473',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 8.819028854370117'],\n",
       " ['Trial 0217 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 448',\n",
       "  'epochs: 1000',\n",
       "  'penalty: 0.0010405149469639172',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 12',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 2',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 8.934073448181152'],\n",
       " ['Trial 0047 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 384',\n",
       "  'epochs: 600',\n",
       "  'penalty: 0.017062104228483796',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 9.15286922454834'],\n",
       " ['Trial 0088 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 480',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.7386827362326284',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 9.202256202697754'],\n",
       " ['Trial 0029 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 192',\n",
       "  'epochs: 400',\n",
       "  'penalty: 0.04612663112880569',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 9.378429412841797'],\n",
       " ['Trial 0067 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 32',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.023821341615471968',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 9.723791122436523'],\n",
       " ['Trial 0026 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 7',\n",
       "  'n_units: 32',\n",
       "  'epochs: 850',\n",
       "  'penalty: 0.012808017413384401',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 9.889667510986328'],\n",
       " ['Trial 0096 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 160',\n",
       "  'epochs: 1000',\n",
       "  'penalty: 0.0018688381153160341',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 10.015196800231934'],\n",
       " ['Trial 0071 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 13',\n",
       "  'n_units: 416',\n",
       "  'epochs: 450',\n",
       "  'penalty: 0.00017206820945417616',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 10.039109230041504'],\n",
       " ['Trial 0148 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 32',\n",
       "  'epochs: 350',\n",
       "  'penalty: 0.022945031905773832',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 10.29016399383545'],\n",
       " ['Trial 0010 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 96',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.0010648671571730146',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 10.701196670532227'],\n",
       " ['Trial 0085 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 32',\n",
       "  'epochs: 1000',\n",
       "  'penalty: 0.01222222058102824',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 10.77501106262207'],\n",
       " ['Trial 0162 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 32',\n",
       "  'epochs: 550',\n",
       "  'penalty: 0.015485112018637575',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 11.021414756774902'],\n",
       " ['Trial 0014 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 128',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.0034095454792915',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 11.28239631652832'],\n",
       " ['Trial 0062 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 13',\n",
       "  'n_units: 192',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.007283176801670784',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 11.502185821533203'],\n",
       " ['Trial 0012 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 256',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.010147695382205002',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 11.553102493286133'],\n",
       " ['Trial 0038 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 224',\n",
       "  'epochs: 800',\n",
       "  'penalty: 0.00015267810642181204',\n",
       "  'activation: elu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 11.807825088500977'],\n",
       " ['Trial 0074 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 13',\n",
       "  'n_units: 352',\n",
       "  'epochs: 600',\n",
       "  'penalty: 0.0010944849649348783',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 11.868724822998047'],\n",
       " ['Trial 0170 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 128',\n",
       "  'epochs: 250',\n",
       "  'penalty: 0.004585897357807218',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 12.226624488830566'],\n",
       " ['Trial 0149 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 128',\n",
       "  'epochs: 1000',\n",
       "  'penalty: 0.01880223735078594',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 12.634273529052734'],\n",
       " ['Trial 0186 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 352',\n",
       "  'epochs: 900',\n",
       "  'penalty: 0.023348203688397955',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 13.029219627380371'],\n",
       " ['Trial 0033 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 8',\n",
       "  'n_units: 384',\n",
       "  'epochs: 50',\n",
       "  'penalty: 0.0016094632283175482',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 13.05878734588623'],\n",
       " ['Trial 0068 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 8',\n",
       "  'n_units: 256',\n",
       "  'epochs: 500',\n",
       "  'penalty: 0.00043626905330378617',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 13.27733039855957'],\n",
       " ['Trial 0025 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 7',\n",
       "  'n_units: 448',\n",
       "  'epochs: 550',\n",
       "  'penalty: 0.06282144425696626',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 13.35293197631836'],\n",
       " ['Trial 0050 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 6',\n",
       "  'n_units: 256',\n",
       "  'epochs: 150',\n",
       "  'penalty: 0.0004859259950440582',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 13.551251411437988'],\n",
       " ['Trial 0027 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 160',\n",
       "  'epochs: 450',\n",
       "  'penalty: 0.04624312775732566',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 13.878043174743652'],\n",
       " ['Trial 0042 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 13',\n",
       "  'n_units: 352',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.09173790617063003',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 13.898481369018555'],\n",
       " ['Trial 0081 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 384',\n",
       "  'epochs: 550',\n",
       "  'penalty: 0.001079534959523365',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 14.631507873535156'],\n",
       " ['Trial 0157 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 8',\n",
       "  'n_units: 128',\n",
       "  'epochs: 350',\n",
       "  'penalty: 0.4230583889192568',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 14.716967582702637'],\n",
       " ['Trial 0079 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 352',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.09664252998384659',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 14.935319900512695'],\n",
       " ['Trial 0092 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 384',\n",
       "  'epochs: 650',\n",
       "  'penalty: 0.0024075509134974284',\n",
       "  'activation: elu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 15.33177661895752'],\n",
       " ['Trial 0095 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 288',\n",
       "  'epochs: 50',\n",
       "  'penalty: 0.18006051047067137',\n",
       "  'activation: relu',\n",
       "  'optimizer: rmsprop',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 15.332966804504395'],\n",
       " ['Trial 0165 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 64',\n",
       "  'epochs: 200',\n",
       "  'penalty: 0.05127431999297023',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 15.641172409057617'],\n",
       " ['Trial 0015 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 192',\n",
       "  'epochs: 450',\n",
       "  'penalty: 0.0024369021993193396',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 15.92436695098877'],\n",
       " ['Trial 0184 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 288',\n",
       "  'epochs: 400',\n",
       "  'penalty: 0.016323448504770112',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 16.04021644592285'],\n",
       " ['Trial 0077 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 13',\n",
       "  'n_units: 416',\n",
       "  'epochs: 50',\n",
       "  'penalty: 0.0020635282787560168',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 18.175321578979492'],\n",
       " ['Trial 0179 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 384',\n",
       "  'epochs: 600',\n",
       "  'penalty: 0.010586089239516728',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 25.069284439086914'],\n",
       " ['Trial 0056 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 7',\n",
       "  'n_units: 352',\n",
       "  'epochs: 300',\n",
       "  'penalty: 0.009383477580097213',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 27.59067726135254'],\n",
       " ['Trial 0069 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 7',\n",
       "  'n_units: 480',\n",
       "  'epochs: 550',\n",
       "  'penalty: 0.00619165251335446',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 28.08220863342285'],\n",
       " ['Trial 0034 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 7',\n",
       "  'n_units: 352',\n",
       "  'epochs: 850',\n",
       "  'penalty: 0.013811279347051434',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 33.14821243286133'],\n",
       " ['Trial 0097 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 13',\n",
       "  'n_units: 288',\n",
       "  'epochs: 950',\n",
       "  'penalty: 0.5787353965845641',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 33.61920166015625'],\n",
       " ['Trial 0011 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 512',\n",
       "  'epochs: 500',\n",
       "  'penalty: 0.004365542211809495',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 36.16033172607422'],\n",
       " ['Trial 0063 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 8',\n",
       "  'n_units: 160',\n",
       "  'epochs: 400',\n",
       "  'penalty: 0.1867283035331111',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 37.01319885253906'],\n",
       " ['Trial 0002 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 32',\n",
       "  'epochs: 700',\n",
       "  'penalty: 0.09053185453325316',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 38.40604782104492'],\n",
       " ['Trial 0073 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 15',\n",
       "  'n_units: 288',\n",
       "  'epochs: 700',\n",
       "  'penalty: 0.0069096097321597995',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 39.07698440551758'],\n",
       " ['Trial 0188 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 12',\n",
       "  'n_units: 384',\n",
       "  'epochs: 1000',\n",
       "  'penalty: 0.008561473993127509',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 40.05314254760742'],\n",
       " ['Trial 0057 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 9',\n",
       "  'n_units: 96',\n",
       "  'epochs: 250',\n",
       "  'penalty: 0.0604472319031661',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 43.6402473449707'],\n",
       " ['Trial 0007 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 8',\n",
       "  'n_units: 224',\n",
       "  'epochs: 50',\n",
       "  'penalty: 0.069157155915656',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 49.648040771484375'],\n",
       " ['Trial 0001 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 10',\n",
       "  'n_units: 288',\n",
       "  'epochs: 350',\n",
       "  'penalty: 0.014159111980082864',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 51.318115234375'],\n",
       " ['Trial 0159 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 13',\n",
       "  'n_units: 512',\n",
       "  'epochs: 700',\n",
       "  'penalty: 0.01148105675532781',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 4',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 3',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 55.26366424560547'],\n",
       " ['Trial 0024 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 96',\n",
       "  'epochs: 400',\n",
       "  'penalty: 0.5943422694535627',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 58.756683349609375'],\n",
       " ['Trial 0051 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 4',\n",
       "  'n_units: 160',\n",
       "  'epochs: 250',\n",
       "  'penalty: 0.09607440956308258',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 59.31422805786133'],\n",
       " ['Trial 0028 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 8',\n",
       "  'n_units: 320',\n",
       "  'epochs: 850',\n",
       "  'penalty: 0.0430515028717487',\n",
       "  'activation: elu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 76.56925201416016'],\n",
       " ['Trial 0043 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 11',\n",
       "  'n_units: 416',\n",
       "  'epochs: 50',\n",
       "  'penalty: 0.03957664007980896',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 77.17292785644531'],\n",
       " ['Trial 0087 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 14',\n",
       "  'n_units: 384',\n",
       "  'epochs: 150',\n",
       "  'penalty: 0.01730729022075027',\n",
       "  'activation: relu',\n",
       "  'optimizer: adam',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 87.73744201660156'],\n",
       " ['Trial 0005 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 8',\n",
       "  'n_units: 128',\n",
       "  'epochs: 500',\n",
       "  'penalty: 0.14326101994785087',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 124.5224380493164'],\n",
       " ['Trial 0065 summary',\n",
       "  'Hyperparameters:',\n",
       "  'n_layers: 7',\n",
       "  'n_units: 320',\n",
       "  'epochs: 550',\n",
       "  'penalty: 0.43907339460312117',\n",
       "  'activation: relu',\n",
       "  'optimizer: adamax',\n",
       "  'tuner/epochs: 2',\n",
       "  'tuner/initial_epoch: 0',\n",
       "  'tuner/bracket: 4',\n",
       "  'tuner/round: 0',\n",
       "  'Score: 125.566162109375',\n",
       "  '']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8faac7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Hyperband' object has no attribute 'get_best_trials'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#from tensorboard.backend.event_processing import event_accumulator\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#best_trial = tuner.oracle.get_best_trials()[0].trial_id\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#trials = tuner.results_summary(num_trials=-1, )\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m trials \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_trials\u001b[49m(num_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m trials\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Hyperband' object has no attribute 'get_best_trials'"
     ]
    }
   ],
   "source": [
    "#from tensorboard.backend.event_processing import event_accumulator\n",
    "#best_trial = tuner.oracle.get_best_trials()[0].trial_id\n",
    "#trials = tuner.results_summary(num_trials=-1, )\n",
    "trials = tuner.get_best_trials(num_trials = -1)\n",
    "trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a57e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_history(best_trial):\n",
    "\n",
    "  acc = []\n",
    "  val_acc = []\n",
    "  loss = []\n",
    "  val_loss = []\n",
    "\n",
    "  for set_data in ['train', 'validation']:\n",
    "    if set_data == 'train':\n",
    "      ea = event_accumulator.EventAccumulator('./logs/Try-2024-4-30/trial_' + best_trial + '/execution0/' + set_data)\n",
    "      ea.Reload()\n",
    "      for i in range(len(ea.Scalars('epoch_loss'))):\n",
    "        acc.append(ea.Scalars('epoch_acc')[i][2])\n",
    "        loss.append(ea.Scalars('epoch_loss')[i][2])\n",
    "        #lr.append(ea.Scalars('epoch_lr')[i][2])\n",
    "\n",
    "  if set_data == 'validation':\n",
    "      ea = event_accumulator.EventAccumulator('logs/scalars/trial_' + best_trial + '/execution0/' + set_data)\n",
    "      ea.Reload()\n",
    "      for i in range(len(ea.Scalars('epoch_loss'))):\n",
    "        val_acc.append(ea.Scalars('epoch_acc')[i][2])\n",
    "        val_loss.append(ea.Scalars('epoch_loss')[i][2])\n",
    "\n",
    "  return acc, val_acc, loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47d2cd0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "DirectoryDeletedError",
     "evalue": "Directory ./logs/Try-2024-4-30/trial_0208/execution0/train has been permanently deleted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\brynj\\Documents\\Mastersverkefni\\lokaverkefni_vel\\.venv\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:88\u001b[0m, in \u001b[0;36mDirectoryWatcher.Load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_LoadInternal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\brynj\\Documents\\Mastersverkefni\\lokaverkefni_vel\\.venv\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:110\u001b[0m, in \u001b[0;36mDirectoryWatcher._LoadInternal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loader:\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_InitializeLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# If it still doesn't exist, there is no data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\brynj\\Documents\\Mastersverkefni\\lokaverkefni_vel\\.venv\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:173\u001b[0m, in \u001b[0;36mDirectoryWatcher._InitializeLoader\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_InitializeLoader\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 173\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GetNextPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path:\n",
      "File \u001b[1;32mc:\\Users\\brynj\\Documents\\Mastersverkefni\\lokaverkefni_vel\\.venv\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:210\u001b[0m, in \u001b[0;36mDirectoryWatcher._GetNextPath\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the next path to load from.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03mThis function also does the checking for out-of-order writes as it iterates\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m  The next path to load events from, or None if there are no more paths.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    208\u001b[0m paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m    209\u001b[0m     path\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m \u001b[43mio_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mListDirectoryAbsolute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_filter(path)\n\u001b[0;32m    212\u001b[0m )\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paths:\n",
      "File \u001b[1;32mc:\\Users\\brynj\\Documents\\Mastersverkefni\\lokaverkefni_vel\\.venv\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\io_wrapper.py:78\u001b[0m, in \u001b[0;36mListDirectoryAbsolute\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields all files in the given directory.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03mThe paths are absolute.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m---> 78\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, path) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\brynj\\Documents\\Mastersverkefni\\lokaverkefni_vel\\.venv\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:768\u001b[0m, in \u001b[0;36mlist_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_directory(path):\n\u001b[1;32m--> 768\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[0;32m    769\u001b[0m       node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    770\u001b[0m       op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    771\u001b[0m       message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find directory \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path))\n\u001b[0;32m    773\u001b[0m \u001b[38;5;66;03m# Convert each element to string, since the return values of the\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# vector of string should be interpreted as strings, not bytes.\u001b[39;00m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Could not find directory ./logs/Try-2024-4-30/trial_0208/execution0/train",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDirectoryDeletedError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m acc, val_acc, loss, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mextract_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_trial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(acc, val_acc, loss, val_loss)\n",
      "Cell \u001b[1;32mIn[19], line 11\u001b[0m, in \u001b[0;36mextract_history\u001b[1;34m(best_trial)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m set_data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     10\u001b[0m   ea \u001b[38;5;241m=\u001b[39m event_accumulator\u001b[38;5;241m.\u001b[39mEventAccumulator(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./logs/Try-2024-4-30/trial_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m best_trial \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/execution0/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m set_data)\n\u001b[1;32m---> 11\u001b[0m   \u001b[43mea\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ea\u001b[38;5;241m.\u001b[39mScalars(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_loss\u001b[39m\u001b[38;5;124m'\u001b[39m))):\n\u001b[0;32m     13\u001b[0m     acc\u001b[38;5;241m.\u001b[39mappend(ea\u001b[38;5;241m.\u001b[39mScalars(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_acc\u001b[39m\u001b[38;5;124m'\u001b[39m)[i][\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\brynj\\Documents\\Mastersverkefni\\lokaverkefni_vel\\.venv\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\event_accumulator.py:343\u001b[0m, in \u001b[0;36mEventAccumulator.Reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads all events added since the last call to `Reload`.\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03mIf `Reload` was never called, loads all events in the file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m  The `EventAccumulator`.\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generator_mutex:\n\u001b[1;32m--> 343\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ProcessEvent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\brynj\\Documents\\Mastersverkefni\\lokaverkefni_vel\\.venv\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:92\u001b[0m, in \u001b[0;36mDirectoryWatcher.Load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mOpError:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directory):\n\u001b[1;32m---> 92\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m DirectoryDeletedError(\n\u001b[0;32m     93\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m has been permanently deleted\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directory\n\u001b[0;32m     95\u001b[0m         )\n",
      "\u001b[1;31mDirectoryDeletedError\u001b[0m: Directory ./logs/Try-2024-4-30/trial_0208/execution0/train has been permanently deleted"
     ]
    }
   ],
   "source": [
    "acc, val_acc, loss, val_loss = extract_history(best_trial)\n",
    "\n",
    "print(acc, val_acc, loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9d610d9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brynj\\Documents\\Mastersverkefni\\lokaverkefni_vel\\.venv\\Lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py:435: UserWarning: Model 'sequential' had a build config, but the model cannot be built automatically in `build_from_config(config)`. You should implement `def build_from_config(self, config)`, and you might also want to implement the method  that generates the config at saving time, `def get_build_config(self)`. The method `build_from_config()` is meant to create the state of the model (i.e. its variables) upon deserialization.\n",
      "  model.build_from_config(\n",
      "c:\\Users\\brynj\\Documents\\Mastersverkefni\\lokaverkefni_vel\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:418: UserWarning: Skipping variable loading for optimizer 'adamax', because it has 2 variables whereas the saved optimizer has 58 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "best_model = tuner.get_best_models()[0]\n",
    "best_model.save(f'./saved_models/nn-{date.today()}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be45d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.fit(X_train, y_train, batch_size = 256, epochs = 100, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394976bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.squeeze(model.predict(X_test))\n",
    "y_true = y_test.values\n",
    "mape = tf.metrics.mean_absolute_percentage_error(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
