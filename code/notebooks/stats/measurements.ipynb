{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 3,
>>>>>>> b04b3c723532e763012997ddf8c08d4e05cf96b2
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from utils.util import getTopLevelPath\n",
<<<<<<< HEAD
    "from datetime import datetime\n",
=======
>>>>>>> b04b3c723532e763012997ddf8c08d4e05cf96b2
    "import numpy as np, pandas as pd, dill as pickle, os"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 4,
>>>>>>> b04b3c723532e763012997ddf8c08d4e05cf96b2
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = getTopLevelPath() + 'data/Measured/10min/Chunks/Nailstripped/'\n",
<<<<<<< HEAD
    "outputfolder = getTopLevelPath() + 'data/Measured/Stats/'\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistributions(withAWSL = False, limit = 20):\n",
    "    pd.options.mode.use_inf_as_na = True\n",
    "\n",
    "    files = [folder_path + file for file in os.listdir(folder_path) if file.endswith('.feather')]\n",
    "    windspeeds = {(0, 5): 0, (5, 10): 0, (10, 15): 0, (15, 20): 0, (20, 25): 0, (25, 30): 0, (30, 35): 0, (35, 40): 0, (40, float('inf')): 0}\n",
    "    gustspeeds = {(0, 5):0, (5, 10):0, (10, 15):0, (15, 20):0, (20, 25):0, (25, 30):0, (30, 35):0, (35, 40):0, (40, 45):0, (45, 50): 0, (45, 50):0, (50, float('inf')):0}\n",
    "    years, months = {year:0 for year in range(1990, 2024)}, {month: 0 for month in range(1, 13)}\n",
    "    winddirections = {(d, d+15): 0 for d in range(0, 360, 15)}\n",
    "\n",
    "    # Ensure consistent lengths for gust_factor keys\n",
    "    gust_factor_keys = [(i, i + 2) for i in np.arange(10, 80, 4)] + [(80, float('inf'))]\n",
    "    # Convert to NumPy array\n",
    "    gust_factor = {key: 0 for key in gust_factor_keys}\n",
    "\n",
    "    # Extract lower and upper bounds of each range\n",
    "    ws_bounds = np.array([list(key) for key in windspeeds.keys()])\n",
    "    wg_bounds = np.array([list(key) for key in gustspeeds.keys()])\n",
    "    wd_bounds =  np.array([list(key) for key in winddirections.keys()])\n",
    "    gf_bounds = np.array([list(key) for key in gust_factor.keys()])\n",
    "    \n",
    "    missing_ws_values = 0\n",
    "    missing_wg_values = 0\n",
    "    missing_wd_values = 0    \n",
    "    missing_gf_values = 0\n",
    "    missing_years_values = 0\n",
    "    missing_months_values = 0\n",
    "\n",
    "\n",
    "    for file in tqdm(files, total=len(files)):\n",
    "        # Example DataFrame\n",
    "        df = pd.read_feather(file)\n",
    "        if withAWSL:\n",
    "            df = df[df.f >= limit]\n",
    "        # Skip year 2019 of station 613 (Selfoss), this is the year that the station was setup and some errors in measurements (fg <= f)\n",
    "        # So all of the measurement from that station in that year are discarded\n",
    "        df = df[~((613 == df.stod) & (2019 == df.timi.dt.year))]\n",
    "        # Extract values from the DataFrame\n",
    "        ws_values, wg_values,  wd_values, gf_values, years_values, months_values = df.f.values, df.fg.values, df.d.values, 10 * (df.fg.divide(df.f, fill_value=float('inf'))).values, df.timi.dt.year.values, df.timi.dt.month.values\n",
    "\n",
    "        missing_ws_values += np.isnan(ws_values).sum()\n",
    "        missing_wg_values += np.isnan(wg_values).sum()\n",
    "        missing_wd_values += np.isnan(wd_values).sum()\n",
    "        missing_gf_values += np.isnan(gf_values).sum()\n",
    "        missing_years_values += np.isnan(years_values).sum()\n",
    "        missing_months_values += np.isnan(months_values).sum()\n",
    "\n",
    "\n",
    "        # Create masks for each range\n",
    "        ws_masks = (ws_values[:, None] >= ws_bounds[:, 0]) & (ws_values[:, None] < ws_bounds[:, 1])\n",
    "        wg_masks = (wg_values[:, None] >= wg_bounds[:, 0]) & (wg_values[:, None] < wg_bounds[:, 1])\n",
    "        wd_masks = (wd_values[:, None] >= wd_bounds[:, 0]) & (wd_values[:, None] < wd_bounds[:, 1])\n",
    "        gf_masks = (gf_values[:, None] >= gf_bounds[:, 0]) & (gf_values[:, None] < gf_bounds[:, 1])\n",
    "\n",
    "        # Initialize counts array with zeros\n",
    "        ws_counts = np.zeros(len(windspeeds))\n",
    "        wg_counts = np.zeros(len(gustspeeds))\n",
    "        wd_counts = np.zeros(len(winddirections))\n",
    "        gf_counts = np.zeros(len(gust_factor))\n",
    "\n",
    "        # Sum the masks along axis 0 to get the count for each range\n",
    "        ws_counts += ws_masks.sum(axis=0)\n",
    "        wg_counts += wg_masks.sum(axis=0)\n",
    "        wd_counts += wd_masks.sum(axis=0)\n",
    "        gf_counts += gf_masks.sum(axis=0)\n",
    "\n",
    "        # Update windspeeds dictionary with the counts\n",
    "        for idx, key in enumerate(windspeeds.keys()):\n",
    "            windspeeds[key] += ws_counts[idx]\n",
    "        # Update windspeeds dictionary with the counts\n",
    "        for idx, key in enumerate(gustspeeds.keys()):\n",
    "            gustspeeds[key] += wg_counts[idx]\n",
    "        # Update windspeeds dictionary with the counts\n",
    "        for idx, key in enumerate(winddirections.keys()):\n",
    "            winddirections[key] += wd_counts[idx]\n",
    "        # Update windspeeds dictionary with the counts\n",
    "        for idx, key in enumerate(gust_factor.keys()):\n",
    "            gust_factor[key] += gf_counts[idx]\n",
    "        years_counts = df.groupby(df.timi.dt.year.dropna()).size()\n",
    "        month_counts = df.groupby(df.timi.dt.month.dropna()).size()\n",
    "        years.update(years_counts)\n",
    "        months.update(month_counts)\n",
    "    years['missing'] = missing_years_values\n",
    "    months['missing'] = missing_months_values\n",
    "    winddirections['missing'] = missing_wd_values\n",
    "    windspeeds['missing'] = missing_ws_values\n",
    "    gustspeeds['missing'] = missing_wg_values\n",
    "    gust_factor['missing'] = missing_gf_values\n",
    "    if withAWSL:\n",
    "        outputfolder_path = outputfolder + \"WithAWSL/\"\n",
    "    else:\n",
    "        outputfolder_path = outputfolder\n",
    "    with open(outputfolder_path + 'windspeeds_stats_' + today + '.pkl', 'wb') as f:\n",
    "        pickle.dump(windspeeds, f)\n",
    "    with open(outputfolder_path + 'gustspeeds_stats_' + today + '.pkl', 'wb') as f:\n",
    "        pickle.dump(gustspeeds, f)\n",
    "    with open(outputfolder_path + 'gust_factor_stats_' + today + '.pkl', 'wb') as f:\n",
    "        pickle.dump(gust_factor, f)\n",
    "    with open(outputfolder_path + 'winddirections_stats_' + today + '.pkl', 'wb') as f:\n",
    "        pickle.dump(winddirections, f)\n",
    "    with open(outputfolder_path + 'years_stats_' + today + '.pkl', 'wb') as f:\n",
    "        pickle.dump(years, f)\n",
    "    with open(outputfolder_path + 'months_stats_' + today + '.pkl', 'wb') as f:\n",
    "        pickle.dump(months, f)\n",
    "    return windspeeds, gustspeeds, gust_factor, winddirections, years, months"
=======
    "outputfolder = getTopLevelPath() + 'data/Measured/Stats/'"
>>>>>>> b04b3c723532e763012997ddf8c08d4e05cf96b2
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def loadDistributions(withAWSL = False):\n",
    "    if withAWSL:\n",
    "        folder_path = outputfolder + 'WithAWSL/'\n",
    "    else:\n",
    "        folder_path = outputfolder\n",
    "\n",
    "    with open(folder_path + 'windspeeds_stats.pkl', 'rb') as f:\n",
    "        windspeeds = pickle.load(f)\n",
    "    with open(folder_path + 'gustspeeds_stats.pkl', 'rb') as f:\n",
    "        gustspeeds = pickle.load(f)\n",
    "    with open(folder_path + 'winddirections_stats.pkl', 'rb') as f:\n",
    "        winddirecions = pickle.load(f)\n",
    "    with open(folder_path + 'years_stats.pkl', 'rb') as f:\n",
    "        years = pickle.load(f)\n",
    "    with open(folder_path + 'months_stats.pkl', 'rb') as f:\n",
    "        months = pickle.load(f)\n",
    "\n",
    "    return windspeeds, gustspeeds, winddirecions, years, months\n",
    "    "
=======
    "def getDistributions(withAWSL = False, limit = 20):\n",
    "    pd.options.mode.use_inf_as_na = True\n",
    "\n",
    "    files = [folder_path + file for file in os.listdir(folder_path) if file.endswith('.feather')]\n",
    "    windspeeds = {(0, 5): 0, (5, 10): 0, (10, 15): 0, (15, 20): 0, (20, 25): 0, (25, 30): 0, (30, 35): 0, (35, 40): 0, (40, float('inf')): 0}\n",
    "    gustspeeds = {(0, 5):0, (5, 10):0, (10, 15):0, (15, 20):0, (20, 25):0, (25, 30):0, (30, 35):0, (35, 40):0, (40, 45):0, (45, 50): 0, (45, 50):0, (50, float('inf')):0}\n",
    "    years, months = {year:0 for year in range(1990, 2024)}, {month: 0 for month in range(1, 13)}\n",
    "    winddirections = {(d, d+15): 0 for d in range(0, 360, 15)}\n",
    "    # Ensure consistent lengths for gust_factor keys\n",
    "    gust_factor_keys = [(i, i + 2) for i in np.arange(10, 80, 4)] + [(80, float('inf'))]\n",
    "    # Convert to NumPy array\n",
    "    gust_factor = {key: 0 for key in gust_factor_keys}\n",
    "\n",
    "    for file in tqdm(files, total=len(files)):\n",
    "        # Example DataFrame\n",
    "        df = pd.read_feather(file)\n",
    "        if withAWSL:\n",
    "            df = df[df.f >= limit]\n",
    "\n",
    "        # Extract lower and upper bounds of each range\n",
    "        ws_bounds, wg_bounds, wd_bounds, gf_bounds = np.array([list(key) for key in windspeeds.keys()]), np.array([list(key) for key in gustspeeds.keys()]), np.array([list(key) for key in winddirections.keys()]), np.array([list(key) for key in gust_factor.keys()])\n",
    "\n",
    "        # Extract values from the DataFrame\n",
    "        ws_values, wg_values,  wd_values, gf_values = df.f.values, df.fg.values, df.d.values, 10 * (df.fg.divide(df.f, fill_value=float('inf'))).values\n",
    "\n",
    "        # Create masks for each range\n",
    "        ws_masks = (ws_values[:, None] >= ws_bounds[:, 0]) & (ws_values[:, None] < ws_bounds[:, 1])\n",
    "        wg_masks = (wg_values[:, None] >= wg_bounds[:, 0]) & (wg_values[:, None] < wg_bounds[:, 1])\n",
    "        wd_masks = (wd_values[:, None] >= wd_bounds[:, 0]) & (wd_values[:, None] < wd_bounds[:, 1])\n",
    "        gf_masks = (gf_values[:, None] >= gf_bounds[:, 0]) & (gf_values[:, None] < gf_bounds[:, 1])\n",
    "\n",
    "        # Initialize counts array with zeros\n",
    "        ws_counts = np.zeros(len(windspeeds))\n",
    "        wg_counts = np.zeros(len(gustspeeds))\n",
    "        wd_counts = np.zeros(len(winddirections))\n",
    "        gf_counts = np.zeros(len(gust_factor))\n",
    "\n",
    "        # Sum the masks along axis 0 to get the count for each range\n",
    "        ws_counts += ws_masks.sum(axis=0)\n",
    "        wg_counts += wg_masks.sum(axis=0)\n",
    "        wd_counts += wd_masks.sum(axis=0)\n",
    "        gf_counts += gf_masks.sum(axis=0)\n",
    "\n",
    "        # Update windspeeds dictionary with the counts\n",
    "        for idx, key in enumerate(windspeeds.keys()):\n",
    "            windspeeds[key] += ws_counts[idx]\n",
    "        # Update windspeeds dictionary with the counts\n",
    "        for idx, key in enumerate(gustspeeds.keys()):\n",
    "            gustspeeds[key] += wg_counts[idx]\n",
    "        # Update windspeeds dictionary with the counts\n",
    "        for idx, key in enumerate(winddirections.keys()):\n",
    "            winddirections[key] += wd_counts[idx]\n",
    "        # Update windspeeds dictionary with the counts\n",
    "        for idx, key in enumerate(gust_factor.keys()):\n",
    "            gust_factor[key] += gf_counts[idx]\n",
    "        years_counts = df.groupby(df.timi.dt.year).size()\n",
    "        month_counts = df.groupby(df.timi.dt.month).size()\n",
    "        years.update(years_counts)\n",
    "        months.update(month_counts)\n",
    "    if withAWSL:\n",
    "        outputfolder_path = outputfolder + \"WithAWSL/\"\n",
    "    else:\n",
    "        outputfolder_path = outputfolder\n",
    "    with open(outputfolder_path + 'windspeeds_stats.pkl', 'wb') as f:\n",
    "        pickle.dump(windspeeds, f)\n",
    "    with open(outputfolder_path + 'gustspeeds_stats.pkl', 'wb') as f:\n",
    "        pickle.dump(gustspeeds, f)\n",
    "    with open(outputfolder + 'gust_factor_stats.pkl', 'wb') as f:\n",
    "        pickle.dump(gust_factor, f)\n",
    "    with open(outputfolder_path + 'winddirections_stats.pkl', 'wb') as f:\n",
    "        pickle.dump(winddirections, f)\n",
    "    with open(outputfolder_path + 'years_stats.pkl', 'wb') as f:\n",
    "        pickle.dump(years, f)\n",
    "    with open(outputfolder_path + 'months_stats.pkl', 'wb') as f:\n",
    "        pickle.dump(months, f)\n",
    "\n",
    "    return windspeeds, gustspeeds, gust_factor, winddirections, years, months"
>>>>>>> b04b3c723532e763012997ddf8c08d4e05cf96b2
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 4,
>>>>>>> b04b3c723532e763012997ddf8c08d4e05cf96b2
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brynj\\AppData\\Local\\Temp\\ipykernel_17712\\3443278443.py:2: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  pd.options.mode.use_inf_as_na = True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f303ff7011b498aae063e995d665b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
<<<<<<< HEAD
    "_ = getDistributions()"
=======
    "def loadDistributions(withAWSL = False):\n",
    "    if withAWSL:\n",
    "        folder_path = outputfolder + 'WithAWSL/'\n",
    "    else:\n",
    "        folder_path = outputfolder\n",
    "\n",
    "    with open(folder_path + 'windspeeds_stats.pkl', 'rb') as f:\n",
    "        windspeeds = pickle.load(f)\n",
    "    with open(folder_path + 'gustspeeds_stats.pkl', 'rb') as f:\n",
    "        gustspeeds = pickle.load(f)\n",
    "    with open(folder_path + 'winddirections_stats.pkl', 'rb') as f:\n",
    "        winddirecions = pickle.load(f)\n",
    "    with open(folder_path + 'years_stats.pkl', 'rb') as f:\n",
    "        years = pickle.load(f)\n",
    "    with open(folder_path + 'months_stats.pkl', 'rb') as f:\n",
    "        months = pickle.load(f)\n",
    "\n",
    "    return windspeeds, gustspeeds, winddirecions, years, months\n",
    "    "
>>>>>>> b04b3c723532e763012997ddf8c08d4e05cf96b2
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 75,
>>>>>>> b04b3c723532e763012997ddf8c08d4e05cf96b2
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "C:\\Users\\brynj\\AppData\\Local\\Temp\\ipykernel_17712\\3443278443.py:2: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
=======
      "C:\\Users\\brynj\\AppData\\Local\\Temp\\ipykernel_17712\\4057473155.py:2: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
>>>>>>> b04b3c723532e763012997ddf8c08d4e05cf96b2
      "  pd.options.mode.use_inf_as_na = True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "d4fd080688164e31b3a819a940c2170e",
=======
       "model_id": "65ce0d8ce8c64d6884d093f02be793a9",
>>>>>>> b04b3c723532e763012997ddf8c08d4e05cf96b2
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
<<<<<<< HEAD
    "_ = getDistributions(True)"
=======
    "windspeeds, gustspeeds, gust_factor, winddirections, years, months = getDistributions()"
>>>>>>> b04b3c723532e763012997ddf8c08d4e05cf96b2
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
