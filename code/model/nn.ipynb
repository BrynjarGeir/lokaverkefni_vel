{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ecc11b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asked ChatGPT for a baseline and this is it\n",
    "# The parameters are the below along with 70 landscape parameters with \n",
    "    #Index(['DateTime', 'lat', 'lon', 'wdir15', 't15', 'ws15', 'pres15', 'wdir150',\n",
    "    #       't150', 'ws150', 'pres150', 'wdir250', 't250', 'ws250', 'pres250',\n",
    "    #       'wdir500', 't500', 'ws500', 'pres500', 'f', 'fg', 'gust_factor'],\n",
    "    #      dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea8aff13",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Skóli\\lokaverkefni_vel\\code\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd, numpy as np, tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c76266",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.abs((y_true-y_pred) / y_true)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eb2141e4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#df = pd.read_feather('E:/Skóli/HÍ/Vélaverkfræði Master HÍ/Lokaverkefni/Data/merged-full-25ms-24hr-28-2-24.feather')\n",
    "#df = pd.read_feather('E:/Skóli/HÍ/Vélaverkfræði Master HÍ/Lokaverkefni/Data/merged-full-W-Landscape-And-Station-Elevations-25ms-24hr-11-3-24.feather')\n",
    "df = pd.read_feather('D:\\Skóli\\lokaverkefni_vel\\data\\merged-full-W-Landscape-And-Station-Elevations-25ms-24hr-11-3-24.feather')\n",
    "df = df[df.f < df.fg]\n",
    "df['gust_factor'] = df.fg / df.f\n",
    "\n",
    "df_unfolded = df.elevations.apply(pd.Series)\n",
    "\n",
    "df = pd.concat([df, df_unfolded], axis = 1)\n",
    "\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a79532fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, -70:] = df.iloc[:, -70:].sub(df.station_elevation, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6f03c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df_landscape_elevation = df.iloc[:, -70:]\n",
    "\n",
    "df_landscape_elevation = (df_landscape_elevation - df_landscape_elevation.mean()) / df_landscape_elevation.std()\n",
    "\n",
    "n_components = 5\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "compressed_features = pca.fit_transform(df_landscape_elevation)\n",
    "\n",
    "compressed_df = pd.DataFrame(data = compressed_features, columns = ['PC' + str(i) for i in range(n_components)])\n",
    "\n",
    "df  = pd.concat([df, compressed_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3281887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cornerFromCenterLand(row):\n",
    "    X, Y, d = row.X, row.Y, row.d\n",
    "    inlandX, inlandY = 520000, 485000\n",
    "\n",
    "    v = (X - inlandX, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2cbc3f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([     'X',      'Y',   'time',  'ws_15', 'ws_250', 'ws_500',  'wd_15',\n",
       "       'wd_250', 'wd_500',   'p_15',\n",
       "       ...\n",
       "             65,       66,       67,       68,       69,    'PC0',    'PC1',\n",
       "          'PC2',    'PC3',    'PC4'],\n",
       "      dtype='object', length=106)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0e64d5b2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "y = df.gust_factor\n",
    "X = df[['Ri_01', 'Ri_12', 'X', 'Y', 'station_elevation'] + ['PC' + str(i) for i in range(n_components)]]\n",
    "\n",
    "# Changing the type of X,y so as to work with Tensorflow\n",
    "X, y = X.values.astype(np.float32), y.values.astype(np.float32)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.fit_transform(X_val)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bc74e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_units = 128\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=n_units, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Dense(units=n_units, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Dense(units=n_units, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Dense(units=n_units, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Dense(units=n_units, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "    tf.keras.layers.Dense(units=1, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c19613c6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "64/64 [==============================] - 5s 12ms/step - loss: 101.5588 - val_loss: 34.8562\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 61.0498 - val_loss: 15.8429\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 42.2420 - val_loss: 10.6266\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 31.0723 - val_loss: 8.6793\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 24.5305 - val_loss: 8.4546\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 20.2408 - val_loss: 8.0156\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 18.1655 - val_loss: 8.4732\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 16.6498 - val_loss: 8.1666\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 15.4485 - val_loss: 8.5872\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 14.5103 - val_loss: 8.0219\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 13.5272 - val_loss: 7.9246\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 12.9022 - val_loss: 8.2714\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 12.5047 - val_loss: 8.0909\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 11.9796 - val_loss: 7.3182\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 11.5622 - val_loss: 7.5276\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 11.1136 - val_loss: 7.2856\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 10.9311 - val_loss: 7.3753\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 10.6435 - val_loss: 7.1030\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 10.1823 - val_loss: 7.0244\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 9.8820 - val_loss: 6.9909\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 9.8711 - val_loss: 7.1909\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 9.3076 - val_loss: 7.1027\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 9.3461 - val_loss: 7.6860\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 9.1028 - val_loss: 7.2730\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 8.9445 - val_loss: 7.5694\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 8.7278 - val_loss: 7.0899\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 8.4383 - val_loss: 7.2591\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 8.2687 - val_loss: 7.8491\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 8.2795 - val_loss: 6.7837\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 8.0811 - val_loss: 7.0418\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 7.8960 - val_loss: 7.1028\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 7.8274 - val_loss: 6.9504\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 7.5887 - val_loss: 6.8297\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 7.5898 - val_loss: 6.8066\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 7.4253 - val_loss: 7.3270\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 7.4663 - val_loss: 6.8393\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 7.2366 - val_loss: 6.8728\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 7.1974 - val_loss: 6.8590\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 7.1072 - val_loss: 6.8938\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 7.0937 - val_loss: 6.7023\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 7.0945 - val_loss: 6.8170\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 7.0452 - val_loss: 6.6792\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 7.0024 - val_loss: 6.7043\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.9707 - val_loss: 6.8930\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.8926 - val_loss: 6.7053\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.8066 - val_loss: 7.0533\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.8160 - val_loss: 7.0420\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.8633 - val_loss: 6.6022\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.7771 - val_loss: 6.7883\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.7842 - val_loss: 6.6272\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.7736 - val_loss: 6.7413\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.7273 - val_loss: 6.9601\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.6884 - val_loss: 6.6314\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.7330 - val_loss: 6.9186\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.8045 - val_loss: 6.6438\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.6402 - val_loss: 6.6487\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.6236 - val_loss: 6.6500\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.7265 - val_loss: 6.7927\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 6.6886 - val_loss: 6.7518\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.6242 - val_loss: 6.5720\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.6402 - val_loss: 6.6331\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.6351 - val_loss: 6.7152\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5886 - val_loss: 6.6878\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 6.6084 - val_loss: 6.7994\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.6016 - val_loss: 6.7237\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.6134 - val_loss: 6.6482\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5809 - val_loss: 6.6265\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5590 - val_loss: 6.6887\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5578 - val_loss: 6.8889\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5857 - val_loss: 6.8193\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5329 - val_loss: 6.7506\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5746 - val_loss: 6.8354\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5938 - val_loss: 6.8073\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5284 - val_loss: 6.7307\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5451 - val_loss: 6.7094\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5615 - val_loss: 6.6093\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5816 - val_loss: 7.0568\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5346 - val_loss: 6.7685\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5362 - val_loss: 6.7345\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.4909 - val_loss: 6.7116\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5024 - val_loss: 7.1783\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5030 - val_loss: 6.6980\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.4833 - val_loss: 6.7737\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.4844 - val_loss: 6.7949\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.4953 - val_loss: 7.0023\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5326 - val_loss: 6.7307\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.4763 - val_loss: 6.6733\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.5103 - val_loss: 6.9446\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.4932 - val_loss: 6.8674\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.4437 - val_loss: 6.6347\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.4541 - val_loss: 6.7083\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.4618 - val_loss: 6.8380\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.4772 - val_loss: 6.6903\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 6.4374 - val_loss: 6.7262\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.4832 - val_loss: 6.6111\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.4800 - val_loss: 6.6590\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.4204 - val_loss: 6.6805\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.3947 - val_loss: 6.5795\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 6.3960 - val_loss: 6.6986\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 6.3695 - val_loss: 6.5309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c00b8e6590>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=mean_absolute_percentage_error)\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs = 100, batch_size = 128, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b8f03a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 2ms/step - loss: 6.2152\n",
      "Model evaluates to: 6.2151641845703125%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mape = model.evaluate(X_test, y_test)\n",
    "print(f'Model evaluates to: {mape}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9d610d9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model.save('./saved_models/nn-12-3-24-14-00.keras')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
