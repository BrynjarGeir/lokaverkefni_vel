{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd, numpy as np, tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from skopt import BayesSearchCV\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Nadam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.abs((y_true-y_pred) / y_true)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(\"E:/Skóli/HÍ/Vélaverkfræði Master Hí/Lokaverkefni/Data/merged-full-W-Landscape-And-Station-Elevations-2-sectors-25ms-24hr-18-3-24-stripped-with-klst.feather\")\n",
    "\n",
    "df = df[df.f < df.fg]\n",
    "df['gust_factor'] = df.fg / df.f\n",
    "\n",
    "df_unfolded = df.elevations.apply(pd.Series)\n",
    "\n",
    "df = pd.concat([df, df_unfolded], axis = 1)\n",
    "\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_elevations = df.columns[-1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, -n_elevations:] = df.iloc[:, -n_elevations:].sub(df.station_elevation, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df_landscape_elevation = df.iloc[:, -n_elevations:]\n",
    "\n",
    "df_landscape_elevation = (df_landscape_elevation - df_landscape_elevation.mean()) / df_landscape_elevation.std()\n",
    "\n",
    "n_components = 10\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "compressed_features = pca.fit_transform(df_landscape_elevation)\n",
    "\n",
    "compressed_df = pd.DataFrame(data = compressed_features, columns = ['PC' + str(i) for i in range(n_components)])\n",
    "\n",
    "df  = pd.concat([df, compressed_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt, sin, cos, acos, pi\n",
    "\n",
    "def cornerFromCenterLand(row):\n",
    "    X, Y, d = row.X, row.Y, row.d\n",
    "    inlandX, inlandY = 520000, 485000\n",
    "\n",
    "    len_v1 = sqrt((X-inlandX)**2 + (Y-inlandY)**2)\n",
    "\n",
    "    v1 = ((X - inlandX)/len_v1, (Y - inlandY)/ len_v1)\n",
    "\n",
    "    outX, outY = X + cos(d * pi / 180), Y + sin(d * pi / 180)\n",
    "\n",
    "    len_v2 = sqrt(outX**2 + outY**2)\n",
    "\n",
    "    v2 = (outX / len_v2, outY / len_v2)\n",
    "\n",
    "    return acos(np.dot(v1, v2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['relativeCorner'] = df.apply(cornerFromCenterLand, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([             'X',              'Y',           'time',          'ws_15',\n",
       "               'ws_250',         'ws_500',          'wd_15',         'wd_250',\n",
       "               'wd_500',           'p_15',\n",
       "       ...\n",
       "                  'PC1',            'PC2',            'PC3',            'PC4',\n",
       "                  'PC5',            'PC6',            'PC7',            'PC8',\n",
       "                  'PC9', 'relativeCorner'],\n",
       "      dtype='object', length=180)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.gust_factor\n",
    "X = df[['Ri_01', 'Ri_12', 'N_01', 'N_12', 'station_elevation', 'relativeCorner'] + ['PC' + str(i) for i in range(n_components)]]\n",
    "\n",
    "# Changing the type of X,y so as to work with Tensorflow\n",
    "X, y = X.values.astype(np.float32), y.values.astype(np.float32)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.fit_transform(X_val)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_search_space():\n",
    "    search_space = {\n",
    "                    'model__n_layers': np.arange(4, 9),\n",
    "                    'model__n_units': [64, 128, 256, 512],\n",
    "                    'model__activation': ['relu', 'elu', 'softmax'],\n",
    "                    'model__penalty': [0, 0.01, 0.1, 1],\n",
    "                    'model__optimizer': ['adam', 'rmsprop', 'adamax']}\n",
    "    \n",
    "    return search_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_layers, n_units, activation, penalty, optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = n_units, activation = activation, kernel_regularizer=l2(penalty), input_shape = (X_train.shape[1], )))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    for _ in range(n_layers):\n",
    "        model.add(Dense(units = n_units, activation = activation, kernel_regularizer=l2(penalty)))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(units = n_units, activation = 'relu', kernel_regularizer=l2(penalty)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(units = 1, activation = 'linear'))\n",
    "\n",
    "    model.compile(optimizer = optimizer, loss = 'mean_squared_error')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn = build_model, verbose = 0, epochs = 200)\n",
    "search_space = build_search_space()\n",
    "\n",
    "kfold = KFold(n_splits = 5, shuffle=True, random_state=42)\n",
    "\n",
    "bayes = BayesSearchCV(estimator = model, search_spaces=search_space, cv = kfold, n_iter = 32, verbose = 2, random_state=42,n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "bayes.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
